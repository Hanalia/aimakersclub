---
author: AI Makers Club
pubDatetime: 2025-07-24T08:19:12.431Z
title: "How Intuit uses LLMs to explain taxes to millions of taxpayers - Jaspreet Singh, Intuit"
slug: _zl_zimMRak
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "인튜잇(특히 터보택스)은 2023년 세금 연도에 4,400만 건 이상의 세금 신고서를 성공적으로 처리했으며, 모든 사용자가 자신 있게 세금 신고를 이해하고 최적의 공제를 받을 수 "
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/_zl_zimMRak/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [How Intuit uses LLMs to explain taxes to millions of taxpayers - Jaspreet Singh, Intuit](https://www.youtube.com/watch?v=_zl_zimMRak)  
**채널명:** AI Engineer

## *인튜잇은 LLM을 통해 수백만 납세자에게 세금 설명을 제공함* 핵심 요약

- 인튜잇(특히 터보택스)은 2023년 세금 연도에 4,400만 건 이상의 세금 신고서를 성공적으로 처리했으며, 모든 사용자가 자신 있게 세금 신고를 이해하고 최적의 공제를 받을 수 있도록 지원하는 것을 목표로 함
- ‘Geno(GenOS)’라는 자사 생성형 AI 운영체제를 기반으로 규모에 맞는 통합 세무 지원 경험을 제공하며, 안전성과 보안, 최신 IRS 규정 반영 등이 필수적으로 고려됨
- 사용자 입력 데이터를 바탕으로 환급액·공제·세액공제 내역을 상세히 설명하는 프롬프트 기반 솔루션을 설계했고, 대규모 프로덕션에는 주로 앤스로픽의 Claude 모델 및 OpenAI의 GPT-4 시리즈를 사용
- 정적인 질의(예: 내 전체 환급 설명)와 동적인 질의(예: 특정 세목에 대한 질문)에 따라 적합한 LLM, 프롬프트, RAG(Graph RAG 포함) 방식을 택해 맞춤 응답을 생성함
- IRS 등 세법 변동에 신속히 대응하기 위해 사내 세무 전문가와 협업하여 프롬프트 설계와 수작업 평가를 시작으로, LLM 기반 자동 평가(LLM as a judge)까지 단계별 평가 체계를 구축
- Claude 3 Haiku 모델을 AWS Bedrock과 연동하여 파인튜닝 실험을 진행, 파인튜닝 후 프롬프트가 짧아지고 지연시간(latency) 감소 및 응답 품질 향상 등의 효과 확인
- 실서비스에선 정밀한 평가지표(정확성, 관련성, 일관성)와 자동 모니터링 체계를 운용, 특히 수치 정보를 별도의 세무 엔진에서 추출해 LLM의 "헛소리(hallucination)"를 방지
- 벤더(LM 제공사) 교체 및 모델 버전 업그레이드 시 ‘벤더 락인’과 모델 호환성, 비용 및 지연시간 관리 등이 중요한 도전과제로 부각됨
- 복잡한 사용자의 세무 상황과 폭주하는 세금 신고 시즌(4월 15일 등) 대응을 위해 다양한 폴백 전략과 사용자 친화적 경험 설계를 중시함
- 질문 유형에 따라 워크플로우를 분기하고, 그래프 RAG 활용 등으로 정밀·개인화된 설명을 제공, 향후 세무 연도에도 신모델 실험 및 사내 자체 모델 개발 지속
- 수작업 평가(세무 전문가)와 자동 평가(LLM as a judge)의 타이밍·역할 분담을 명확히 정의, 품질 일관성 보장을 위해 계속된 고도화 작업 진행

---

## 세부 요약 - 주제별 정리

### 터보택스는 연 4,400만 건 이상의 세금 신고 고객에 LLM 기반 설명을 제공함

- 인튜잇 터보택스는 2023년 세금 연도에 4,400만 건 이상의 세금 신고서를 처리
- 목표는 모든 사용자가 자신 있게 신고서를 이해하고, 받을 수 있는 모든 공제와 세액공제를 빠짐없이 안내받게 하는 것
- 사용자는 터보택스에서 개인정보 입력, 적용 가능한 공제·크레딧 검토, 환급 내역 등 일련의 세무 입력 흐름을 경험
- 각 단계별로 LLM이 맞춤 정보를 분석, "이 공제는 이렇게 적용됩니다" 등 사용자의 이해를 돕는 설명을 실시간으로 제공함

### ‘Geno’(GenOS)라는 생성형 AI OS 기반의 대규모 세무 지원 플랫폼을 구축

- 인튜잇은 자체 개발한 생성형 플랫폼 GenOS(Geno)를 기반으로 서비스 고도화
- Geno는 UI(Genux), 오케스트레이터(여러 LLM 해법을 분기·조율), 보안 등 다양한 컴포넌트로 구성
- 수많은 팀이 개별 LLM 솔루션을 개발하는 환경에서, 사용 사례별 ‘올바른 LLM·도구’를 선택할 수 있게 설계
- 인튜잇 Assist란 명칭으로 End-to-End 고객 지원 경험을 제공

### 사용자 세금 데이터 설명을 위해 프롬프트 기반과 양방향 질의 시스템을 도입함

- 초기에는 프롬프트 중심(prompt-based)의 설명형 LLM 솔루션으로 시작
- 대표 예시: 사용자의 ‘환급액’ 계산 과정(공제, 세액공제, standard deduction, W2 원천징수 등)을 각각 세부 설명
- 프롬프트텔릿을 통해 “당신의 환급액은 ○○○에 근거해 산출되었습니다” 식으로 상세 분해 설명
- 프로덕션 적용에는 Claude(Anthropic)이 주력 모델, OpenAI GPT-4도 QA용으로 병행
- 정적인 질문(요약 설명 등)과 동적인 질문(특정 항목 차등 질문 등)에 따라 프롬프트 템플릿과 LLM 활용 모델을 분리
- IRS 등 세무 데이터 최신성 보장을 위해 RAG(검색증강생성), Graph RAG 방식을 데이터 접근 계층에 적용

### RAG와 그래프 RAG 결합으로 개인화·정확도 높은 답변 품질을 실현함

- 전통 RAG와 그래프 RAG(관계지식 기반)를 하이브리드로 구성
- 정규 RAG 대비 Graph RAG가 더 유용하며, 특히 ‘사용자 맞춤화’에 탁월한 효과
- 예시: 사용자가 복잡한 상황(주택 보유, 주식, 배우자 근로 등) 입력 시, 사용자 상황에 맞는 세법 조항 및 예시를 연동해 설명 제공
- 향후 신규 세무 연도(23→24년) 등 변화 시에도 신속한 룰·지식 반영 가능

### 세무 전문가와 협앙해 평가 체계를 단계별로 고도화하고 있음

- 수작업(manual)은 세무 분석가(실제 세법 전문가)들이 프롬프트 설계 및 1차 품질평가를 담당
- 세무 전문가가 프롬프트 엔지니어 역할까지 수행하여 초반 데이터셋·메트릭 정의 지원
- 이후 생성된 골든 데이터셋/지침에 따라 자동 평가(LLM as a judge) 체계로 전환
- 모델, 시스템 변경(모델 업그레이드, 세법 변동) 발생 시에는 세무 전문가 중심의 수작업 평가 반복
- AWS Ground Truth 등 도구를 활용해 평가용 데이터 구조화 및 golden sample 구축

### 파인튜닝된 Claude 3 Haiku(AWS Bedrock 연동) 활용이 응답성 향상에 기여함

- Claude 3 Haiku 모델을 AWS Bedrock 상에서 domainspecific 데이터로 파인튜닝한 사례 소개
- 파인튜닝 후 장점은 더 짧은 프롬프트, 더 낮아진 응답 지연시간(latency), 품질 향상 등
- 파인튜닝 모델은 특정 상황에서는 지나치게 한정/특화될 수 있음을 확인, 범용성·적용범위 균형을 모색
- 실무에서는 프롬프트 사이즈 감소, 응답 속도 개선이 핵심 KPI

### 평가 체계는 정확성, 관련성, 일관성에 철저히 집중함

- S/W 개발 전체 라이프사이클에서 ‘무엇이든 평가한다’ 원칙 준수
- 평가지표로 accuracy(정확성), relevancy(관련성), coherence(일관성)을 정의
- 수작업 평가(초기, 주요 변화 시), 자동 평가(소규모 프롬프트 변경, 주기모니터링) 병행
- 자동 모니터링으로 실사용자의 실제 LLM 응답 샘플링·평가 진행(실시간 품질 감시)
- 제품 출시 전 반드시 세부 기준, golden data set 확보 필수

### 수치 정보는 세무 엔진에서 추출, LLM의 hallucination을 원천 차단함

- 실제 수치(예: 환급액, 공제액)는 직접 LLM 계산 X, 사내 세무 엔진(Knowledge Engine)에서 제공
- LLM은 설명문을 제시하되, 숫자 등은 사전에 검증된 데이터만 삽입
- ML 기반 보안모듈이 LLM 응답 내 숫자값이 실제 엔진 데이터와 일치하는지 추가검증
- 서비스 출고 전 ‘헛소리 수치 방지용’ 안전장치 다중화 실시

### 벤더 락인, 응답 지연, 시즌성 트래픽 등 대규모 운용 과제가 존재함

- 대규모 LLM 활용은 수백~수천만 달러 규모의 벤더(클라우드, OpenAI 등) 장기 계약을 수반
- 벤더 락인(prompts, API 등) 및 연간 모델 업그레이드시의 부작용(이식성, 성능차이, 비용상승 등) 공존
- LLM은 전통 백엔드 서버와 달리 SLA가 낮고, 복잡한 입력 시 latency(3~10초 이상)가 큰 도전과제
- 납세자 폭주가 심한 4월 15일 등 시즌성 트래픽에도 대응할 폴백전략, UX 최적화 필요

### 질문 유형에 따라 워크플로우와 솔루션을 분기하여 대응함

- 사용자의 질문은 ‘제품 이용 방법’, ‘나의 세무상황별 질의’ 등 다양
- 세무 전문가와 별도의 팀이 각 질문 유형(플로우)별로 적합한 LLM/도구/플랜을 맞춤 설계
- Planner 시스템이 사용자의 질의 목적을 분류해 알맞은 솔루션(flow, rag 등)으로 라우팅
- FAQ, 사례 질문(손자 교육비 공제 가능?), 복잡한 입력 상황 등 모두 맞춤 응답으로 처리

### LLM 기반 자동 평가(LLM as a judge)와 수작업 평가는 단계별로 분리 운영됨

- 개발 초기(프롬프트 설계, 베이스라인 구축)는 수작업(세무 전문가) 평가가 필수
- 프롬프트 미세 조정·기존 워크플로우 소규모 변경 등에는 LLM 자동 평가(예: GPT-4 계열)로 빠르게 검증
- 세무 연도 변경 등 주요 룰·모델·프롬프트 대폭 변화 시에는 다시 수작업 평가로 품질 재확보
- 나머지는 LLM judge가 golden 데이터셋을 기준으로 정확성 판별

### 법적 리스크와 개인정보 보호, 컨트롤에 각별히 유의함

- 잘못된 세무 응답은 법적 소송으로 이어질 위험이 크므로, 비즈니스 특성상 법률·프라이버시 규제 준수 필수
- 사내 privacy/security 팀과 긴밀히 협업, 모든 데이터셋은 사용자 동의(consented Data)만 사용
- 세무 전문가·ML팀이 응답 검증 및 guardrail 다중화로 최종 응답의 합법성, 안전성 유지
