---
author: AI Makers Club
pubDatetime: 2025-08-01T08:19:31.311Z
title: "[Full Workshop] Building Conversational AI Agents - Thor Schaeff, ElevenLabs"
slug: MPtCBaZn84A
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "이 워크숍은 11랩스(11 Labs)에서 제공하는 다국어 대화형 AI 에이전트 구축 방법과 도구를 개발자 중심으로 상세히 설명함 주요 워크플로우는 음성 → 텍스트(ASR) → LL"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/MPtCBaZn84A/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [[Full Workshop] Building Conversational AI Agents - Thor Schaeff, ElevenLabs](https://www.youtube.com/watch?v=MPtCBaZn84A)  
**채널명:** AI Engineer

## *대화형 AI 에이전트 구축 워크숍: 11랩스 활용법* 핵심 요약

- 이 워크숍은 11랩스(11 Labs)에서 제공하는 다국어 대화형 AI 에이전트 구축 방법과 도구를 개발자 중심으로 상세히 설명함
- 주요 워크플로우는 음성 → 텍스트(ASR) → LLM(대형 언어모델) → 텍스트 → 음성 변환(TTS) 단계로 이루어짐
- 11랩스는 자체적으로 LLM(지능 모델)은 제공하지 않고, OpenAI GPT-4o, Google Gemini 등 외부 LLM을 연동
- 99개 언어를 지원하는 최첨단 음성 인식(ASR) 모델을 제공하며, 화자 분리, 단어별 타임스탬프, 오디오 이벤트 태그 기능 탑재
- 5,000개 이상의 다양한 언어·악센트의 음성(TTS) 라이브러리와 퍼블릭 마켓플레이스 운영, 음성 제공자는 로열티 수익 획득 가능
- 에이전트별로 언어와 목소리를 세밀하게 지정하고, 대시보드 및 API, 다양한 SDK(자바스크립트, 파이썬 등)로 앱에 통합 가능
- 랭귀지 디텍션·자동 스위칭, 함수 호출(웹훅 연동) 등 다양한 시스템 도구와 기능 사용 가능
- 실시간·저지연·멀티에이전트 구성 방법, 대형 지식베이스 연동(RAG), 엔터프라이즈 환경에서의 대화 지연 극복법 등 심층 질의응답 포함
- 악의적(사기 등) 남용 방지를 위한 실시간 모니터링, 워터마킹, 라이브 보이스 검수 등 다중 안전장치 개발 현황 소개

---

## 세부 요약 - 주제별 정리

### 11랩스와 워크숍 소개, 참여자 안내 및 지원 프로그램

- 11랩스는 대화형 AI, 음성합성 및 개발자 경험에 특화된 플랫폼임을 알림
- 개발자 경험 담당 Thor Schaeff와 동료가 진행, 문서화, 피드백 채널 독려
- 슬라이드 및 안내 자료 QR코드 공유, 참가자 이메일 기입 시 3개월 체험 크레딧 지급 안내
- API 버전/클라이언트 업데이트 등은 X(Twitter) 계정(11 Labs Devs) 팔로우 권장
- 참가자 다국어 언어 수요(포르투갈어, 스페인어, 헝가리어, 중국어, 힌디어, 타밀어 등) 파악
- 유머러스하게 AI가 생성하는 ‘개 짖는 소리’ 등 사운드 이펙트 모델, 드럼머신 데모도 공유

### 실제 대화형 AI 에이전트 전체 파이프라인 구조와 11랩스의 역할 설명

- 사용자 음성을 텍스트화(ASR), 텍스트를 대형 언어 모델로 처리하여 응답 생성, 응답을 음성으로 변환하는 구조
- LLM(지능)은 11랩스가 직접 제공하지 않고, GPT-4o, Gemini 등 외부 연동 혹은 자체 튜닝 모델(OA API 호환) 가능
- 음성 → 텍스트 → 언어모델 → 텍스트 → 음성의 표준 파이프라인을 선호, 텍스트 기반 중간 처리가 모니터링 및 통제가 유리
- 실시간성 극대화를 위해 모델들이 물리적으로 가까이 배치되어 레이턴시를 최소화

### 99개 언어 지원 ASR(음성 인식) 모델 상세 소개 및 실제 활용 데모

- 2024년 최신 런칭된 ASR 모델은 99개 언어 지원, 속도·정확도 업계 선도
- 기능: 화자 분리, 단어별 타임스탬프, cough/laugh 등 오디오 태깅, API 구조화 데이터 반환
- Telegram 봇 데모: 음성 메시지나 비디오를 포워딩하면 자동으로 언어 감지 후 텍스트 변환·전달
- 싱가포르 영어, 스코틀랜드 영어 등 다양한 억양 및 발음 케이스에도 높은 인식률 시연
- 현장 녹음 음성 메시지, 잡음 있는 오디오, 방글라데시 이슈 관련 영어 등 다양한 사례 실시간 변환 시연

### 대형 언어모델(LLM) 연동 구조와 커스텀 LLM, 스트리밍 응답 처리

- 지능/대화는 OpenAI GPT-4o, Google Gemini 등에서 담당, 커스텀 튜닝 LLM도 OA API 호환이면 통합 가능
- LLM의 응답이 스트리밍되면 바로 음성합성하고, 대화의 흐름과 즉각성을 유지
- 높은 호환성과 자유로운 인프라 구성 지원

### 5,000+종 음성(TTS) 라이브러리, 음성 마켓플레이스 및 음성 할당 세부 방법

- 11랩스 내 5,000개 이상 다양한 목소리 선택 가능(언어, 악센트, 성별, 연령 메타 태그)
- 사용자는 직접 자신의 목소리를 클론, 퍼블릭 마켓플레이스 게재, 사용될 때마다 로열티 지급
- $500만 이상이 누적 지급되었으며, 지역·악센트별 특화 음성(브라질 포르투갈어, 체나이 타밀어 등) 손쉽게 지정 가능
- 실제 예시: "German engineer" 등 개인 게시 음성 시연, 각 언어별 세밀한 목소리 할당법 및 대시보드 사용법 설명

### 에이전트 설정 예시: 싱가포르 4개 공식 언어 대화형 에이전트 구성

- 싱가포르 공식 4개 언어(영어, 표준중국어, 말레이어, 타밀어) 및 일본어, 힌디어 등 다양한 언어 참조
- 31개 언어 지원 중, 차기 V3 모델에서 99개로 확대 예정
- 대화형 AI 에이전트 대시보드 내에서 LLM, 지식베이스(문서, 웹사이트), RAG, 함수 및 시스템 도구(언어 감지 등) 연동 가능
- 랭귀지 디텍션 시스템 툴을 활성화하여 다국어 자동 감지/스위칭, 프롬프트에 따른 커스텀 가능
- 실제 시연: 영어로 질문, "힌디어로 전환" 요청, 중국어 발음 등 다양한 언어 처리 과정 직접 데모

### 다양한 앱·환경에서의 활용 예시와 개발 방법 안내

- 대시보드 UI 내 설정뿐 아니라, API로 세밀한 요소까지 구성 가능
- JS SDK, 파이썬 SDK, Next.js/파이썬 샘플 등 제공, 하드웨어(예: Raspberry Pi) 연동 예시
- 마켓플레이스 구축시 에이전트 대량·자동 설정을 위한 API/MCP 서버, 자연어 기반 에이전트 생성 명령 가능

### 세부 질의응답: 언어 감지 프로세스, 멀티언어 스위칭, 함수 호출 등 심층 해설

- 각 언어별 별도 TTS를 지정 가능, 음성 인식(ASR)이 확률 기반으로 언어 판별 후 해당 언어 TTS로 응답
- 시스템 도구(언어 감지)는 ASR 결과의 신뢰도 점수로 스위칭, 목소리는 언어별 직접 할당
- 함수 호출(웹훅 등): 서버사이드 도구(예: CRM, cal.com API)와 연동해 일정 조회·등록 등 수행 가능
- 다양한 LLM(Flash/Flashlight 등)과 발화모델 활용, 가격과 레이턴시 고려하여 선택 가이드

### 저지연성(낮은 레이턴시) 달성, 복수 에이전트·오케스트레이션 관리 팁

- 저지연 대화형(콜센터/전화) 에이전트 구현 시, LLM 및 음성모델 크기·위치 최적화, Flash류 모델 사용 추천
- 장시간 상호작용(예: 요리 동반 AI) 땐 비용 부담 있음, 별도 세일즈팀 통한 커스텀 가격상담 가능
- 멀티 에이전트 구성: 각각의 태스크별 별도 에이전트와 LLM을 설정, 라우팅 시스템 도구로 사용자가 인지 못한 채 투명하게 전환
- 툴/지식베이스 연동 시 반응 시간, 타임아웃(최대 120초), 대기 메시지 등 자연스러운 대화 흐름 유지 방법 안내
- 장기/비동기 작업, 웹소켓 통한 실시간 정보 주입 가능 여부 등 추가 해설

### 멀티언어 혼합 입력/출력 지원, 언어 학습 등 특수케이스 및 한계

- 한 입력 내 언어 혼합(코드스위칭)시, 두개까지는 감지/인식률 양호하나, 3개 이상 동시 사용 시 성능 저하 경향
- 언어 교차 발음·정확도 문제, 음성과 텍스트 경로간 한계, 언어교육 등 특수 용도 상담 사례 언급(Supernova)
- LLM 프롬프트 조정 등의 개선 가능성 언급, 오픈AI 실시간(음성→음성) 방식은 보다 나은 성능일 수도 있음을 논의

### 악용(사기 등) 방지 위한 실시간 안전장치·정책 소개

- 11랩스는 https://11labs.io/safety 등에서 다양한 실시간 모더레이션 도구 개발 및 안내
- 보이스 라이브러리 공개시 금칙어/표현 지정, 라이브 모더레이션 가동
- 생성된 모든 음성에 워터마킹 부여, 계정별로 트레이싱 가능, 악용/사기 시 계정 정지 및 당국 통보 가능
- 프로페셔널 보이스 클론 시, 임의 문장 읽기를 강제해 본인 인증 절차 적용

### 음성·입력 커스터마이즈(발음 사전 등) 및 특수 기업 환경의 요구 반영

- TTS(텍스트→음성)시 발음 사전(프네틱 알파벳) 제공하여 약어/고유어 등 사용자 개별 발음 지정 가능
- STT(음성→텍스트)는 특정 약어/고유어 변환 튜닝 기능은 현재 미지원, LLM 프롬프트 등 우회적 방법 안내
- 실제 SAP 등 현업 기업 사례와 3자 특수 약어 사용 등 맞춤 사례 논의

### 엔터프라이즈, 어바타 활용, 외부 제품과의 통합 질문 사례

- Nvidia Tokkio(토키오) 등 외부 플랫폼 내 11랩스 TTS 활용 가능성, 애니메이션/립싱크 등 추가 스택 통합 여부 질의
- 11랩스는 외부 파트너(헤드라, 헤이젠 등)와 아바타 영역에서 협업 중이며, 직접 솔루션 제공은 미정
- 구체적 파이프라인과 추가 기술 협력 여부는 추후 안내

### 마무리 및 추가 자료/질문 안내

- 참가자 대시보드→대화형 AI→에이전트 생성 후 다양한 언어·음성·기능 직접 실습 권장
- 실시간 질의응답 이후에도 부스 및 이메일 소통 안내, 공식 문서(도큐먼트) 및 다양한 예제 적극 활용 권장
- 크레딧 링크, 지원 문의, 기타 안내로 마무리
