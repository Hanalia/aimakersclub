---
author: AI Makers Club
pubDatetime: 2025-09-24T23:47:38.263Z
title: "AI Engineer Paris 2025 (Day 2)"
slug: wyUdpmj9-64
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "**AI Engineer Paris 2025 둘째 날 컨퍼런스**는 다수의 글로벌 연사(35명+)와 기업, 스타트업이 참여하는 5개 트랙, 500건+ 발표 제안, 다양한 부스와 워"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/wyUdpmj9-64/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [AI Engineer Paris 2025 (Day 2)](https://www.youtube.com/watch?v=wyUdpmj9-64)  
**채널명:** AI Engineer

## *AI 엔지니어 파리 2025 (Day 2)* 핵심 요약

- **AI Engineer Paris 2025 둘째 날 컨퍼런스**는 다수의 글로벌 연사(35명+)와 기업, 스타트업이 참여하는 5개 트랙, 500건+ 발표 제안, 다양한 부스와 워크샵으로 규모 있게 개최됨.
- **에이전트, MCP 프로토콜, 오픈 모델, 생성형 미디어, 인프라 등** AI 최신 기술 및 실제 적용사례를 심도 있게 다룸.
- **Neo4j의 CEO Emil Eifrem**은 미래 AI 애플리케이션 데이터 계층의 4가지 핵심 요건과 이를 위한 그래프 기반 접근, 실 사례 및 데모로 설명.
- **Docker VP Tushar Jain**은 “에이전트는 새로운 마이크로서비스”라는 비전 아래, 에이전트 패키징(CAgent) 및 MCP 서버 신뢰·표준 카탈로그 구축 진척 소개.
- **GitHub VP Martin Woodward**는 MCP 프로토콜 발전사, 실전 운영 경험, 도구 동적 선언, 보안·인증, 신규 오픈 소스 MCP 레지스트리 등을 상세히 공유.
- **COB CEO Yan Leger**는 AI 에이전트 시대의 인프라 변화(다양한 하드웨어, 샌드박스·스케일투제로), 실제 대규모 안전 운영을 위한 기술 스택 및 병목 관리 방법을 구체적 매커니즘 차원에서 시연.
- **Black Forest Labs 공동창업자 Andreas Blattmann**이 선도적 이미지 생성·편집 모델 Flux의 원리(특히 Latent Flow Matching 및 Adversarial Diffusion Distillation)와 가장 빠른 inference 달성 방법, 생태계 규모·데모 공개.
- **H사 CTO Lawrence**는 컴퓨터 UI 기반 에이전트(래퍼적 자동화, 전문화 모델 OLO)의 필요성과 강점, 현황·벤치마크, 오픈웨이트 공개 의의, 실제 사용자 시나리오 구체 도출.
- **Neo4j, HuggingFace, Arise AI, ZML, Llama Index, Google DeepMind, Qout 등 AI 산업 리더 기업**들이 AI 실용화, 열린 생태계, 인프라, 도구/표준, 모델·앱 개발 지원 프로그램, 커뮤니티 참여 강조.
- **실제 현장 데모 및 코드, 데이터, 패키지, 오픈 레지스트리 등 현업 활용 가능한 구체 리소스** 제시, 누구나 시작해볼 수 있음을 강조.
- **각 세션마다 현업의 실제 과제·트렌드·애로사항** 중심으로 실질적 인사이트와 구체적 대응 방법 공유.

---

## 세부 요약 - 주제별 정리

### 컨퍼런스 구조와 주요 행사, 운영 방식이 업계의 새로운 협업·학습의 장을 제공함

- 5개 트랙, 35명+ 연사, 글로벌(미국, 스웨덴·독일 등) 참가자, 500건+ CF 제출, 500명+ 규모 등 대형 행사로 구성됨.
- 다양한 부스와 스폰서 참여(예: COB, Docker, Neo4j, Arise AI, HuggingFace 등), 모두 현장 교류와 네트워크 중심으로 운영.
- 앱을 통한 트랙/세션 정보 확인, 부스·워크샵·카페 등 자체 인프라 지원, 참가자-스폰서-엔지니어 간 연결을 독려.
- 모든 세션은 기록/유튜브 업로드 예정으로, 지식 공유 강화.
- 스폰서십은 Sentry, Arise AI, DeepMind, Algolia, Docker(플래티넘), Neo4j(플래티넘) 등 다양한 수준의 지원/연계.

---

### Neo4j CEO: AI 애플리케이션 데이터 계층은 실질적 ‘4대 속성’을 충족해야 혁신적 응용이 가능함

- “AI 중심의 데이터 계층은 구조화·비구조화·반구조화(3종) 데이터를 단일 레이어에서 처리, 저장, 검색, 트랜잭션 범위로 관리할 수 있어야 한다.”
- 단순 벡터DB의 한계(시맨틱 검색만으로 부족) → 구조화/비구조화 데이터의 융복합 필요성 제시.
- 엔티티 추출·연결의 예시(Andreas/He/ABK → Named Entity Recognition, Entity Resolution)는 향후 AI앱 개발의 핵심 기법이 됨을 강조.
- 실시간/통합 조인(앱 내 데이터, 랙 코퍼스, 에이전트 메모리 간)을 데이터 계층에서 제공해야 성능/복잡성/신뢰성 문제를 근본적으로 해소.
- 1st party(직접 수집) 데이터와 파생(derived, 예: 랙에서 온 가이드 등) 데이터의 명확 구분/통제 기능 필수(예: 마크업, 변경·배포 정책).
- 위 4대 속성을 실제로 구현하기 위한 Neo4j의 진행 상황을 짧은 데모(위키피디아 파리 문서→지식그래프화, 엔티티 추출/검색)로 시연.
- “미래의 대규모 AI 앱은 이러한 데이터 계층 위에서만 가능하다”는 비전을 객관적·구체적으로 제안.

---

### Docker VP: 에이전트 시대엔 ‘에이전트 표준 패키징·카탈로그·보안 생태계’가 SaaS/컨테이너 못지않게 중요

- 에이전트를 단일 마이크로서비스처럼 컨테이너화하여 패키지를 표준화(CAgent 도구, Agentfile 개념 등), OCR registry/hub로 공유·배포·재사용을 실험 중.
- MCP 서버(기능 서버)도 컨테이너 패키징, 신뢰 검증 및 공식 카탈로그 제공(MCP toolkit, Docker Desktop의 UI 통합 관리/연동).
- 공식 hub 내 MCP 서버/에이전트의 신뢰도, 버전 관리, security(루그풀 등) 기능 중심의 생태계 구축.
- Notion→GitHub issue 자동 등록, 도구/비밀값 구성, 오플리셜 MCP 서버, 워크플로우 자동화 데모 실행.
- 향후 standardized packaging, agentfile, 보안 추가 예정. 커뮤니티 피드백 적극 수렴 의사 표명.

---

### GitHub VP: MCP 프로토콜의 실제 도입·운영 경험에서 얻은 ‘도구 선언’, ‘동적 탐색’, ‘보안 인증’, ‘레지스트리’의 실전 교훈

- CoPilot의 초창기~2025년 현재 1,500만 명+ 사용 현황, 기능호출(function calling, 2023.6 첫 등장)→확장성 기반 도구에 최적화.
- MCP(Multi-Client Protocol): 도구 선언/발견, 리소스 단독 접근, 서버-클라이언트 상호 작용(샘플링, 루트, 유저 LLM 활용), 프롬프트, dynamic discovery, elicitation(질의/의사결정 수렴 등) 포함.
- 실제 도입 시 최대 교훈은 도구 과다 제공시 LLM 혼동·성능 저하(LangChain의 연구 데이터). → 다이내믹 도구 탐색·동적 활성화/비활성화 지원이 중요.
- 설치·업그레이드·호환성 문제: 로컬 MCP는 개발 단에서 가장 빨라 실험에 좋으나, 실제 서비스/엔터프라이즈에선 원격 MCP 서버, 공식 인증 절차, OAuth 기반 통합 인증 필수.
- 오픈 MCP 레지스트리(2025년 2주전 출시): 중앙 API/레포/인기도 등 신뢰 기준 제공, 개별/기업/커뮤니티 각각 독립적 등록소 분산 권장(독점 방지, 보안/트러스트 제어).
- LLM의 MCP 서버 구축은 코드 몇줄도 가능(VSCode가 유일하게 스펙 전부 지원), 실제 상용화 고려시 보안·업데이트·자동화 중요.
- 학생/주니어 개발자 교육에도 올바른 MCP 생태계 습득과 팀 기반 시너지 강조.

---

### COB CEO: 에이전트 중심의 AI 인프라는 ‘다양한 하드웨어, 샌드박스, 고속 부팅, 비용 최적화, 보안’이 핵심 조건

- AI 클라우드 인프라는 초기 LLM-GPU 중심 단순 구조(2023년)→2025년 Agent, VLM, 비전/코딩 모델, MCP, 다양한 하드웨어(GPU/CPU/Accelerator) 공존의 복합 생태계로 진화.
- 각 워크로드별 하드웨어 타입(대형훈련 GPU, 소형 튜닝/추론엔 AMD·새 Accelerator, Agentic는 CPU 등) 구체 제시.
- 에이전트 탑재시 샌드박스(비신뢰/비결정적 코드), 고속 에페머럴 환경(잠깐 실행 후 소멸), 대량(일일 10,000개+) 동시 컨테이너 자동 배포·격리 필요.
- 병목 포인트는 네트워킹, 이미지 풀링, 런타임 기동 등. 프리엠티브 부팅, 이미지 캐시, 네트워크 최적화로 극복.
- 사용되지 않는 에이전트 리소스 고효율 관리 위해 ‘scale to zero’, ‘autoscaling’, 메모리 스냅샷(100~200ms 재기동) 등 첨단 기법 적용.
- GPU 샌드박스에도 확장, AI 개발자들이 손쉽게 안전한 대규모·꿈의 속도 환경 조성 가능함을 지향.

---

### Black Forest Labs: Flux 모델은 텍스트-이미지 생성/편집 모두에서 신규 알고리즘으로 ‘초고속·초고품질·대규모 생태계’ 구축

- Flux 모델은 BFL(2024년 4월 설립, 8월 런칭, 40명/독일+SF), 텍스트-이미지 생성+편집, 오픈소스/프리미엄 3단 구조 제공(Flux Pro(API상용), dev(오픈가중치), Chanel(경량/입문)).
- 오픈파인튜닝/로라 생태계, HuggingFace 기준 업계 최대 세부 튜닝 사례로 증명.
- 기존 제품<->이미지 편집 기능 통합(Flux Context, 2025년 6월공개), 캐릭터 일관성·스타일 변환·로컬·글로벌 편집·스케치→렌더·비즈니스 활용 등 폭넓은 usecase.
- 근간 원리: Latent Flow Matching(고효율 잠재공간 생성), Adversarial Diffusion Distillation(교사-학생 네트워크·수십 배 속도화, 디코더 최소화).
- 실제 데모: 축구 유니폼→로고 위치·배경 변화→스타일 변환→사람화→회화화 등 수 초 내 실시간 파이프라인.
- 이론적: 대규모 모델일수록 1-step generation 도달 가능, 고차원 변환 함수 표현력 제공(속도/품질 동시 혁신).
- 오픈웨이트와 상용모델 구조 병행, 커뮤니티/연구/실제 현업 영동 커스터마이징 모두 지원.

---

### H사 CTO: 인간 수준의 자유로운 컴퓨터 UI 자동화 ‘에이전트’는 범용 LLM보다 특화·오픈모델로 실제성과 비용 효율성 모두 극대화

- 컴퓨터 사용자 에이전트: 실제 인간과 동일 방식(화면 캡처+마우스/키보드 동작), RPA와 달리 유연성·복원성·길항적 엔터프라이즈 환경까지 처리 가능.
- UI 기반 다중 사이트/앱 조작 데모(구글 플라이트: 날짜·환승·달력 검색·드롭다운 조작·입력·분류 등)—기존 RPA 대비 1프롬프트, Adaptivity/TR, 서버·로컬 가능한 OLO 모델 제공.
- 실제 성능: WebVoyager 벤치마크(600개 실험), GP(T)계열 대모델 대비 5x 이상 비용 효과, Localization 특화 모델은 범용 VLM보다 Substantial하게 outperform. 파트로 프론티어 증명.
- 훈련: 오픈 OLO(Quen 2.5VL 파인튜닝), 직접 데이터를 모아(Screenshot-Intent-Coordinates), SP/QA/Mu dataset·synthetic trajectory·RL(RPO)까지 단계별 적용.
- 오픈웨이트 전략: 신뢰성·재현성·적극적 커뮤니티·고객 독립성·기술적 정직성·직원 동기 강화 등 다차원적 이점.
- 실제 연구는 Web→Desktop/Mobile로 확장, 오류 사례·카테고리 분류, 인간+AI 학습 강화, 앞으로 Surf showcase/Portal 공개(추론 API, 웹 인터페이스).
- 비즈니스 모델은 가치 기반(건별 과금 아닌 소비 증대 대비 일부 차지). 실제 배포 시 권한·사용자 동의·보안 등 다양한 이슈 구체적 논의.

---

### Neo4j/다중 에이전트 구조 데모: 데이터 지향 ‘그래프 RAG 에이전트’의 설계, 다중전문화/휴먼인더루프·자동화의 실제 절차 공개

- 데이터 그래프 구축을 위한 멀티에이전트(사용자 의도 이해 → 데이터 원천 스캔/추천 → 데이터 모델 제안 → 그래프 생성 → 쿼리 추천 등) 설계 구현.
- 각 에이전트는 구조화/비구조화/그래프 RAG에 특화, 일반 대형 모델 보다는 특수형 모델 활용 시 성능 및 유지성이 비약적으로 향상.
- 실제 영상 데모 : BOM(구성품) 그래프 설계·승인·생성→쿼리 수행→Neo4j 데이타베이스 내 연결관계 시각화까지 full-run 제공.
- 오픈 소스 전체 코드 제공, 도입 엣지 케이스·실전 활용법 공유.

---

### HuggingFace: 오픈 LLM은 이미 ‘일상적 실전 수준’, 높아진 품질/접근성/효율성/확장성/프로덕션 지원까지 실현

- 오픈 LLM(Deepseek R1, Quen 등)은 벤치마크(평균점수/절대점수) 기준 Proprietary 대형모델(GPT-5, Claude Sonnet 등)에 근접. 일부 세부 태스크에서 상회.
- 실제 성능지표: GPD-5 high(67점), GPD-OSS(58점), 대다수 오픈모델 10위권 진입.
- 접근 방식: 즉시사용 API/Managed 배포/직접 배포(내부 GPU/클라우드) 3단계, 2025년 현재 Chat Completions 등 인터페이스 표준화로 개발/운영 쉬워짐.
- 신뢰성/유연성(예: Anthropic 장애 사례, “Not your weights, not your brain”)
- 트렌드(2025): Reasoning 표준화(DeepSeek R1 COT 오픈→작은 모델 디스틸→추론 모드 전파), 컨텍스트 창 확대(128K→100만~1천만), 운영/성능 효율화(Quant 4bit, ChatML 포맷, 툴콜/SCALING), 비용 급감 그래프.
- 제한점: 범용 추론(General Reasoning), End-to-End Multimodal은 아직 Proprietary모델(특히 OpenAI) 우위. 안전·가이드라인/Jailbreak scaffolding 필요.
- 도입 전략: “오픈 우선”, 동일 테스트셋 결과 비교, 프롬프트 조정→실전 도입을 적극 권고.

---

### Arise AI: ‘시스템 프롬프트 학습(Prompt Learning)’으로 에이전트가 실환경서 스스로 진화해야 실효적 성과 가능

- 현장 피드백(온라인 ver eval, Hacker News 등): 에이전트는 고정 프롬프트/계획/도구/컨텍스트에서는 금방 망가짐, 진화형 프로세스 필수.
- Andrej Karpathy의 System Prompt Learning(가장 인간처럼, 프리트레이닝·파인튜닝과 달리 ‘즉각적 예외 피드백’을 시스템 프롬프트에 직접 추가)
- 실제 Coding Agent(Codellama 기반) 사례: Sweetbench 등 코드 버그 수정 태스크, 초기 프롬프트+룰 없는 상태(31% 정답률), 에러시 해설 달아 LLM이 룰에 영어로 규칙 추가→Prompt Iteration수차례→max 45%로 15%p+ 상승.
- 설명형 피드백+분류화된 Error(summary설명)을 Prompt로 루프, 실제 성능 지표/Train/Test/Blind를 실시간 체크하며 overfitting 방지.
- Prompt Learning은 딥스파이 등 기존 Prompt Optim 프레임워크보다 설명/다차원 정보, Self-improvement에 더 가까움. 앞으로 자동화형 prompt optimization 추세.
- 적용 범위: 코드 에이전트뿐 아니라 Structured JSON/Wep페이지 추출/고객분류 등 다양한 Task에서도 Accuracy 수직 향상 입증.
- 시스템 설계: Human-in-the-loop Evaluations, 지속적인 Online Eval 및 Auto-iteration, Prompt 성능 비교를 통한 최적 운영.

---

### ZML: Transformer의 한계(N^2 Attention)을 ‘그래프화/분산 실행’으로 돌파, ‘실제 무제한 컨텍스트 + CPU/네트워크 적합화’ 진화

- Attention 구조의 본질(Softmax→Sparse→대부분 불필요 연산), 이를 ‘그래프 매핑’하여 유의미 노드만 연산 시 log(N) 복잡도로 개선.
- 기존 GPU는 분기(branching) 처리 나쁨→CPU가 유리, KV 캐시를 GPU에서 분리(시스템 메모리/네트워크 분산가능), 모델상 GPU만, KVC는 CPU/네트워크로 수직 확장.
- NVLink/Infiniband가 아닌 10G ethernet(16ms)=>kernel bypass(DPDK)로 이론치(16µs→20µs), 실제로 Fast path 구현, 대규모 모델을 단일 GPU(GPU 32B/32GB 위)에서 Unique하게 실행 성공(데모 : Attention만 죽이면 inference중지).
- 미래에는 Universal Chip지원/동시성/메모리 효율 극대화, 오픈소스 프레임워크로 커뮤니티, 초고성능·저지연 환경을 제공 목표.

---

### Llama Index: 현실적 ‘노트북 LM 대체 오픈소스’ 패키지, 재사용·복합→MCP툴통합까지 실전 템플릿으로 공개

- Notebook LM의 전기능(파일업로드/문서요약/FAQ/마인드맵/오디오/플래카드/비디오/문서관리/문서채팅 등) 벤치마크로 3대 목표: 복잡문서 대응, 기능 재사용성, 워크플로우 제어.
- Llama Index 오픈소스 프레임워크·Llama Cloud 서비스 활용, Llama Parse/Extract 기능으로 업로드→구조 데이터화, 팬딕틱 스키마, 커스텀 구성/모델.
- 직접 작성한 Workflows 클래스(이벤트 기반, 단계 스텝별 입력출력, 모든 주요 로직 MCP tool call화), 추후 각 기능 단독 MCP서버/워크플로우 모듈로 outside 사용 가능.
- 마인드맵 자동 생성/문서 채팅/테이블 및 이미지 추출/팟캐스트 생성/관찰성(Observability) 연동.
- Demo: IKEA 주방 가이드 문서→Q&A·요약·마인드맵·FAIR 초반 노트북 자동생성→Document Chat 및 질의·인용 참조 자동 추출/설명/소스 판별.
- 개발프레임워크 우열은 개발자 경험, 연구 최신성, 관찰성 등 차원에 따라 선호차 존재.
- 커뮤니티 오픈소스이므로 자유롭게 기여/확장/조합 가능. Postgres는 mindmap 등 부가 데이터 로컬 저장용도로만 최소 사용.

---

### Google DeepMind: Gemini·VEO·Genie 등 ‘다중모달/다형태/로컬 친화’ 모델군과 Buidl기능 등 AI 서비스 신경계를 선도

- Gemini 2.5 Pro/Flash/Image Preview(Nanobanana): 이미지/비디오/오디오/텍스트/코드/다국어 등 별도의 샘플 없이 멀티모달 입력+출력 일원화(예: Robotics·스마트글래스·음성그라운딩·학교 숙제·실시간 UI 탐색 데모).
- AI Studio: 실시간 SDK(GenAI, VertexAI) 통합, 자연어 프롬프트로 앱 스케치/배포(CloudRun), 시연(웹캠→DnD캐릭터+스탯생성→구글클라우드에 자동 배포).
- Gemini Live: 실시간 언어변환, 다국어 입력받아 상대 모국어로 구사, UI인식 및 질문 응답, 구글검색 연동, 코드 실행, 화면공유 등 일상적 업무 지원.
- Google Collab 내 자동 EDA/ML모델 자동 계획→코드→실행→결과해석 pipeline, 과거 scikit-learn 기준 본인 경험 대비 혁신적 설명.
- VEO3: 최첨단 동영상생성, 영상+프롬프트+음성 동시 생성/캐릭터 일관성/프레임 보간/아웃페인팅 등 확장, 실제 CF광고 스타일 제작 사례 시연.
- Genie3: 프롬프트/입력 이미지로 Immersive 3D월드 생성, 내부 상태 연속성/상호작용/환경 변화 반영.
- Gemma 3N 등 소형(4B~27B) 오픈모델, 1세대 Gemini(1.5, Pro) 능가, 로컬 호스팅/수백억 매개변수도 단일 H100서 실행, 크롬/모바일 내장·온디바이스 서비스 미리보기.
- 오픈 및 로컬 우선, 스타트업 혁신 친화(적은 인원으로 대규모 시스템 실현), 창업자 지원 프로젝트 강화 메시지.

---

### Qout: 오픈, 저지연, 초실제감 AI 음성/음향 생성, 다방향·다기능(실시간 번역/청자변환/멀티발화/분리전사 등) 풀두플렉스를 실전 수준으로 선보임

- QAI: 파리 기반, 비영리 AI 연구소(2022 설립, Xavier Niel/Eric Schmidt 후원), 개방/협업/아카데미아 파트너십, 모든 산출물 오픈(코드/모델/HF/논문).
- 기존 TTS/ASR/변환/임직/에이전트 등 폐쇄형 → 다수 실시간 쌍방향, NPC, 맞춤형 미디어, 퍼스널 어시스턴트 등 대규모 상용화 기반.
- 품질지표: Full-Duplex 발화, 세계 최초 실시간 동시 대화, 중복·중첩 발화 자연처리(20% 겹침), REST/Speech2Speech+텍스트 에이전트 연결 등.
- 핵심: Mimi(초고압축 음성코덱), 오디오토큰 변환→LMM, Quadratic→Fast“라이트”화, Multi-stream modeling(프렌치→영어, 음성→텍스트 등 모두 동일 구조).
- 실전 데모: 강한 잡음 내/사무실, 실시간 번역(비행기 모드), 동시발화 인식/변환/출력, 실시간 전사, 타자-발화동시 출력 등 구체적 시연.
- 오픈: Pretrained 모델, 파이토치 코드, gradio/web UI 제공. LA Province, 맞춤형 청취 뉴스 등 실제 파트너링 중.
- 스케일: 1개 H100서 320 동시 대화, Whisper/Chatterbox 대비 100배+ Throughput, 낮은 메모리/실수율. 각종 데모 및 애플리케이션-파트너십 오픈 프로토콜/테스트 진행 중.
- 대규모 상용/비장사적 시나리오(게임, 고객센터, 에듀테크, 로컬 디바이스 등) 양방향/실시간/맞춤형 음성 AI에 대한 근간 인프라 추진.

---

### 전체 마무리: 커뮤니티, 인프라 기업, 프로덕트, 스타트업, 오픈생태계, 실제 운영과 현장 적용을 결집하여 AI Engineer시대 혁신 뒷받침

- 각 핵심 기업/연사/프로젝트들은 오픈소스/표준화/실천위주 지향, 실전 인프라/툴/API/레지스트리 바로 활용 강조.
- 엔지니어 간 교류, 직접 데모, 신속 피드백, 스타트업·학생·경력개발·기술 혁신 등 다양한 구성원이 공존하는 현장 전문성 확보.
- AI Engineer/Paris 2025는 미래 AI 혁신에 필요한 데이터 계층, 인프라, 표준, 자동화, 전문화, 오픈 모델, 실전 서빙·운영 기법, 그리고 커뮤니티의 실제 실행 동력을 모두 한자리에 집결시킨 것으로 결론.
