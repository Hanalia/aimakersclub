---
author: AI Makers Club
pubDatetime: 2025-08-21T23:47:30.035Z
title: "My Top 20 Lessons from Building 100s of AI Agents (Super Actionable)"
slug: OFfwN23hR8U
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "본 영상은 Dynamus 커뮤니티 런칭과 Archon 출시, 회원 1,000명 돌파를 기념하여 제작자가 직접 수백 개의 AI 에이전트를 구축하며 얻은 가장 실용적이고 중요한 20가"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/OFfwN23hR8U/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [My Top 20 Lessons from Building 100s of AI Agents (Super Actionable)](https://www.youtube.com/watch?v=OFfwN23hR8U)  
**채널명:** Cole Medin

## *수백 개의 AI 에이전트 구축에서 얻은 20가지 핵심 교훈*  핵심 요약

- 본 영상은 Dynamus 커뮤니티 런칭과 Archon 출시, 회원 1,000명 돌파를 기념하여 제작자가 직접 수백 개의 AI 에이전트를 구축하며 얻은 가장 실용적이고 중요한 20가지 교훈을 '라이브 이벤트'로 제공
- AI 에이전트란 환경과 상호작용하며 목표 달성을 위한 다양한 행동 경로를 LLM(대형 언어모델)로 스스로 결정하는 프로그램임을 핵심 정의로 제시
- 에이전트 구성요소(시스템프롬프트, LLM, 도구, 메모리)를 기반으로, 각 요소마다 실전에서 부딪치는 문제와 해결전략, 경험적 팁을 구조적으로 전달
- 가장 큰 도전과제는 '환각(hallucination, 거짓 답변)'으로, 여러 에이전트를 조합할수록 복합적 확률로 환각이 증폭될 수 있음을 수치(예: 각 95% 성공률의 3개 에이전트 → 전체 성공률 86%)와 함께 설명
- 환각 방지 핵심 전략으로 ◦전자동화 대신 시간절약식 자동화를 할 것, ◦계획 및 프로토타이핑(2단원 할애) 반드시 거칠 것, ◦AI 가드레일(입력/출력 검증 소형 LLM 추가), ◦전문화 에이전트 분리, ◦시스템프롬프트 내 구체적 예시 사용을 반복 강조
- 시스템프롬프트 설계시 부정구 피하기, 모순/중복된 설명 배제, 프롬프트 버전관리(Langfuse 등 도구 제시), 도구 사용법·출력포맷·예시 등 최대한 자세히 명시할 것을 지속 강조
- LLM 교체(예: GPT-4 Turbo→GPT-4o)시 프롬프트 및 도구 세팅 재점검 필수, LLM별 강점 상이·벤치마크 맹신 금지, 컨텍스트 길이 관리(특히 대화기록·롱프롬프트 시 시스템프롬프트 소실 위험) 유념
- 메모리 시스템(단기/장기)에서는 환각의 반복 가능성, RAG에서의 메모리 활용 및 최적화, 대화기록에 반드시 도구호출 요청·응답 포함 필요성 등 실제 에이전트 구현시 필수적 세부 노하우 제시
- 도구 설계법(정의·인자·출력·예시·오류처리·포맷 최적화)과 함께, 다양한 프레임워크(N8N, Pyantic AI, Crew AI, LangChain 등) 적용 시 유의사항을 코드 템플릿·실사례로 공개
- 마지막 Q&A 세션에서 에이전트 구조 및 LIMIT, 시스템프롬프트 최적화법, 이미지 분류 적용, 커뮤니티 학습자료 이용법, 도구 활용 트러블슈팅 등 실무적 질문에 상세 피드백 제공

---

## 세부 요약 - 주제별 정리

### AI 에이전트는 환경과 상호작용하며 목표 달성을 위해 비결정적 행동을 선택함

- AI 에이전트란, 대형 언어모델을 이용해 환경과 상호작용하고(예: Slack 메시지 읽기, Gmail/Outlook 이메일 작성 등) 목표 달성을 위해 다양한 행동절차(1~n단계)를 스스로 판단해 실행하는 프로그램임을 명시
- 기존 소프트웨어는 '동일 입력→동일 출력'의 결정론적 방식이었으나 에이전트는 비결정적(노-디터미니즘) 특성 보유: 같은 입력에도 각 실행마다 결과가 다를 수 있음
- 에이전트의 독자적 판단력(계획, 도구선택, 환경 탐색)은 큰 효율·자동화 혁신을 가져오지만, 잘못된 판단시 예측불가 오류와 위험성 동반
- 에이전트의 주요 구성요소 네 가지: 시스템프롬프트(행동·톤 지시), 대형언어모델(두뇌), 도구(외부 환경 조작·정보 획득), 메모리 시스템(단기/장기+RAG)
- 단기 메모리는 대화기록, 장기 메모리는 선호·목표, RAG 등 지식 데이터베이스까지 포함

---

### 환각(hallucination) 문제는 복합 실행 시 폭발적으로 증가할 수 있으므로 반드시 대비가 필요함

- 가장 치명적 과제는 LLM 및 에이전트의 '환각'(거짓 판단/허위 생성); 자신있게 거짓 답변 후 실제 존재하지 않는 출처까지 인용하는 등의 현상 다수
- 환각이란 단순 실수 이상, 자신감 있는 오답 제시를 의미하며, AI 실무자–개발자 사이에서 과도하게 빈번히 언급됨
- 에이전트 자동화의 위험 예시: 이메일 완전 자동 회신은 AI에게 과도한 책임을 부여; 초안 자동화 + 사람의 최종 확인(시간 절약형·책임 분산)의 형태가 권장됨
- 여러 에이전트를 조합하는 멀티 에이전트 워크플로우(예: A2A/MCP 프로토콜 등)에서는 각 에이전트가 95% 성공률일 때 전체 성공률은 86%로 하락; 개별 에러가 누적되며 시스템 신뢰도 저하
- 환각 방지에는 자동화의 범위를 '전체 대체' 대신 '보조+시간절약'으로 제한하고, 시스템 구조 설계 단계에서 책임 분산과 결과 검증 체계를 반드시 포함해야 함

---

### 에이전트 구축 시 '기획 및 프로토타이핑'에 충분히 시간을 들이면 전체 개발 효율이 극적으로 향상됨

- 빠른 구현 유혹을 뿌리치고, 목표/도구/역할 등 에이전트 설계 방향을 명확히 기획·프로토타이핑 하는 초기 단계에 5시간을 투자하면, 이후 20시간 이상의 개발·리팩토링 시간을 절감 가능
- 실제 초기에 기획을 생략했다가 수많은 시간 낭비 후 처음부터 다시 짜야 했던 사례 반복 경험 강조
- Dynamus 강의 및 실무에서도 전체 로드맵의 두 개 모듈을 전적으로 기획·프로토타이핑에 할애

---

### 환각 저감 실전 전략은 가드레일, 전문화, 예시 활용 등 다층적으로 적용해야 한다

- AI 가드레일(Guardrail)은 입력/출력 단계 별로 소형 LLM 추가 배치; 예) 여행 일정 추천시 예산 미달(예: 두바이 500달러 여행 요청) → LLM이 입력 불가 판단·에러 전환, 일정 일수 미스매치시 재생성 유도함
- Guardrail용 LLM은 신속·가벼운 모델 활용(GPT4.1 mini 등); 이상 감지시 실패 경로로 분기하거나, 사용자 재요청·에이전트 재호출 로직 삽입 가능
- 에이전트 역할을 세분화(전문화 에이전트): 하나의 에이전트에 과도한 역할을 몰아주는 대신, 도구별/업무영역별 에이전트 분리(오케스트레이터 에이전트→각 전문화 담당 에이전트)로 오류 위험 감소
- 단, 전문화 분리로 오케스트레이터의 역할 선택 오류 위험(복합 환각)이 다시 일부 증대됨. 역할명, 프롬프트 내 역할정의 명확화로 대체로 극복 가능
- 시스템프롬프트 및 도구 설명에 '구체적 예시(Examples)' 다수 첨부: 최신 AI 코딩 어시스턴트(예: Vzero, Cursor, Bolt New 등) 역시 프롬프트 구조에서 실제 예제와 포맷, 인자를 상세 명시함

---

### 시스템프롬프트 설계 시 부정·모순·관리 문제에 주의하면 환각 및 예측불가 행동을 대폭 줄일 수 있음

- 부정(negative) 구문(예: "복잡한 언어는 사용하지 마세요")은 LLM이 길이가 길어질수록 부정어를 무시하며 반대로 동작하는 경향
- 긍정적인 명령(예: "초등학생 수준의 쉬운 영어로 설명해 주세요")으로 바꿔서 전달해야 명확성 확보 가능
- 시스템프롬프트 내 모순(예: "간결하고 효율적으로 답하라"→"포괄적으로 역사·이론·응용까지 모두 답하라" 등)을 반드시 제거해야 일관된 답변 가능
- 실제 '친절·유연' 지시와 '시간 엄수' 같은 디테일 툴 사용법 지시가 충돌하여 캘린더 도구 활용 오류(예약가능 시간 외 시간 안내 등) 발생 사례 공유
- 프롬프트 버전 관리 필수: 코드처럼 이전 버전 복구 용이하도록 GitHub 내 관리, Langfuse 등 프롬프트 관리 도구 활용 권장
- 프롬프트 과다 및 오류시 재빠른 복구·비교가 가능

---

### LLM(대형 언어모델) 선택 및 교체는 의외로 많은 부작용을 내재하므로 충분한 테스트와 컨텍스트 최적화가 필요함

- LLM 교체시(예: GPT-4 Turbo → GPT-4o) '더 좋은' 모델임에도 기존 프롬프트·도구와의 미세호환 문제로 의외로 심각한 환각 등 부작용 다발
- 프롬프트 재최적화 필요(타 모델별 명령문 이해법, 행동특성 상이)
- 실제로 bolt.diy, bolt.new 등 실전 서비스에서도 LLM 업그레이드 후 시스템 프롬프트 대대적 수정 사례 있음(Claude 3.5→3.7 Sonnet 등)
- LLM별 강·약점 상이(Gemini 2.5 Pro: 창작·라이팅 보조에 강함, Claude 3.7 Sonnet: 코딩 에이전트에 적합 등); 벤치마크점수 및 주관적 호불호에만 집착하지 말고 다양한 모델 실테스트 필수
- OpenAI 등 128K 컨텍스트 한계, 로컬 LLM은 32K 제한 등 메모리 한계 내에서 시스템프롬프트(가장 앞부분)부터 삭제되므로, 장기 대화 또는 대용량 문서 처리시 필히 한계 체크·컨텍스트 압축 전략 마련

---

### 메모리 시스템(단기/장기)에서는 '과거 환각 반복'과 RAG 활용법에 세심하게 신경써야 성능 저하를 방지할 수 있음

- 단기 메모리(대화기록)에서 이전 환각/오류 지식이나 도구실패 경험이 이후 질의에서도 무비판적으로 반복·전파됨(예: 잘못된 출판 연도 반복, 동일 도구 호출 오류 반복)
- 장기 메모리–RAG는 본질적으로 동일 구조(벡터DB 내 객체: 문서/메모리 구분)이며, query expansion, re-ranking 등 RAG 최적화 노하우가 장기 메모리 최적화에도 직접 적용됨
- 도구 호출 시 요청/응답을 반드시 대화기록(conversation history)에 포함해야, 후속 질문에서 실제 과거 호출정보 재활용 및 불필요한 반복 호출 방지 가능
- 예: RAG 도구로 첫 번째 질의에서 받아온 벡터DB chunk를, 이후 연관 질문에서 추가 레트리브 없이 재활용 가능

---

### 도구(툴) 설계 시 목적·파라미터·예시·오류처리·출력포맷 등 섬세한 설계가 에이전트 전체 품질을 좌우함

- 도구 설명은 구체적 목적(what), 호출 방식(how), 인자 설명(args) 등을 최대한 상세히 명시: 시스템프롬프트에는 도구 간 작동 원리를, 도구 설명 자체에는 개별 도구의 사용법을 담음
- 복잡한 도구는 인자 사용 예시(포맷, 쿼리 구조 등)를 실제값으로 제시, 간단한 도구(무인자)는 생략 가능
- 모든 도구 코드는 오류(예외)처리 루틴 포함: AI가 잘못 호출(Open API 파라미터 오류 등)해도 전체 애플리케이션이 중단되지 않음; 오류 메시지를 직접 에이전트에 반환해 재호출 및 자체 롤백 논리 가능
- 결과 반환시 LLM이 실제로 필요한 최소한의 정보만 엄선(대형 JSON 등 과다 전송 지양); 예: Shopify API 호출시 불필요한 메타데이터 제외, 본문 데이터만 전송
- 전체 도구 설계 템플릿 예시(try/except, 실제 반환 포맷, 마크다운 출력 등)와 함께 다양한 프레임워크(N8N, Pyantic AI, CrewAI, LangChain 등) 공통 적용 원칙 강조

---

### 마크다운 포맷, 명확한 구조화, 예시 적용 등 프론트엔드 포맷팅에 신경쓰면 인간-에이전트 소통 효율성이 대폭 향상됨

- 마크다운은 섹션, 소제목, 코드블록 등 명확한 구조 제공으로 에이전트가 정보 구조를 빠르고 명확하게 파악·활용 가능
- 실제 Readme 파일 예시에서 마크다운 구조 활용을 제안하며, 복수 도구에서 공통적으로 사용
- 출력 포맷 표준화(예시 첨부, 인자/결과 정형 배열, 에러 메시지 추가 등)는 복잡한 멀티 에이전트 시스템에서 특히 효율성 향상

---

### Q&A: 에이전트 수·프롬프트 최적화·이미지 분석·학습자료 관리 등 실전적 질문에 대한 상세 답변

- 오케스트레이터 하위 에이전트 수가 많을수록(15~20명 이상) LLM이 혼란을 느낄 수 있지만, 역할 구분이 뚜렷하면 상당 수준까지 무리 없이 운영 가능; 너무 다수일 땐 다층 오케스트레이터, 혹은 별도 앱으로 분리 권장
- 시스템프롬프트 최적화시 LLM 평가(LLM as a judge, 자동 평가 및 프롬프트 튜닝 활용)와 수동 조정 병행 권장
- 이미지 분석 사례에서 LLM+비전 기능 결합(이미지 인풋+속성 예시→추후 분류 시 예시 활용) 가능하며, 직접 훈련보다는 투입 프롬프트 내 참고 사례 방식 사용
- 커뮤니티 자료는 Dynamus 홈페이지–이벤트 캘린더–과거 이벤트 항목 선택→녹화 영상/자료 30분 내 업로드 방식; 라이브 및 워크숍 자료도 동일 구조
- 도구 미작동시 프레임워크(N8N, Pyantic AI 등)에 따라 구체적 연결오류, 호출 문제 여부 등 점검
- 시스템프롬프트 손상 예방법(프롬프트 메모리화), 칼렌들리 등 1:1 세션 지원 여부(오피스아워로 대체), 서버리스/전반적 배포모듈 안내 등 다양한 실무 파트너십/지원 구조 명시
- embedding 모델 파인튜닝·RAG 정확도 개선 등 고급화 주제 강의 예정 예고 및 커뮤니티 PR(풀리퀘스트) 방법 안내

---

### 결론: 실전 경험 기반 정교한 노하우가 AI 에이전트 개발의 성공률과 효율성을 결정함

- 본 강의의 20가지 교훈은 단순 기술 요약이 아닌, 수백 개 실무 구축 경험에서 도출된 정교한 시행착오, 각 단계별 위험 관리, 최적화 루틴, 프롬프트·도구·메모리 구조의 진화적 개선안 포함
- 수많은 Q&A를 통해 다양한 업무영역·프레임워크·실전 이슈에서의 적용 및 실질적 해결법이 공유됨
- 핵심은 '극한 디테일(구체적 예시, 구조화, 반복·검증)'과 '책임 분산', '환각 방지', '최신 기술의 실전 검증과 최적화–관리'임
- 항상 프롬프트, 에이전트 구조, 도구, 메모리, LLM 별 실전 테스트와 구조화된 버전관리를 병행하는 것이 성과 향상의 지름길임
