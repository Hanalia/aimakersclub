---
author: AI Makers Club
pubDatetime: 2025-08-03T08:19:21.801Z
title: "How to Improve your Vibe Coding - Ian Butler"
slug: g03m-WFEu1U
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "이안 버틀러(Bismouth CEO)는 에이전틱(Agentic) 코딩 에이전트의 버그 탐지 실효성과 단점을 평가한 신규 벤치마크 결과를 발표함 현존 에이전트(Devon, Curso"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/g03m-WFEu1U/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [How to Improve your Vibe Coding — Ian Butler](https://www.youtube.com/watch?v=g03m-WFEu1U)  
**채널명:** AI Engineer

## *바이브 코딩(Vibe Coding) 실력을 높이는 방법 — Ian Butler* 핵심 요약

- 이안 버틀러(Bismouth CEO)는 에이전틱(Agentic) 코딩 에이전트의 버그 탐지 실효성과 단점을 평가한 신규 벤치마크 결과를 발표함
- 현존 에이전트(Devon, Cursor 등)의 실제 버그 탐지율은 10% 미만에 불과하며, 오탐(false positive) 비율이 매우 높음(예: Cursor의 경우 97%)
- 벤치마크에 사용된 6개 에이전트 중 절반이 10% 이하의 실탐율을 기록했고, 900개 이상 버그 리포트 중 거짓 경고가 다수였음
- 일부 에이전트는 한 작업에서 70개의 문제를 지적했으나 모두 실제 버그가 아님
- 실제 개발 현장에서는 오탐/불필요 알림(alert fatigue)이 많아져 신뢰성과 효과가 떨어지고, 버그가 실제 서비스까지 전파되는 결과가 초래됨
- 해결책으로 첫째, 에이전트에 구체적인 버그 중심 규칙 파일(룰) 제공 필요
- 둘째, 코드베이스 내 맥락(context) 관리가 중요하며, 에이전트의 논리적 연결 유지가 어려운 점이 취약점임을 지적
- 셋째, '사고 모델(Thinking Models)'은 복잡한 버그 탐지 능력이 월등하므로 사용할 것을 추천
- 룰 파일에 OWASP Top 10 등 구체 보안 항목, 명시적 버그 유형 명기, 수정 후 테스트 통과 요구 등의 방법 제안
- 사용자는 코드 변경점(diff) 및 주요 파일의 맥락 정보를 직접 관리하며, 구조적 인벤토리(indexing) 마련을 권장함
- 사고 모델의 경우 동작 내 추론 과정(trace)이 깊어 실제로 더 복합적인 버그 탐지에서 우월성 입증
- 그러나 여전히 에이전트는 한 번에 전체 파일을 완전히 커버하지 못하는 한계가 남아있음
- 발표 말미에는 Bismouth 솔루션 기능(자동 PR, 다양한 플랫폼 연동, 보안 취약점 탐지, 온프레미스 배포 등) 및 상세 벤치마크 결과 확인 방법 안내

---

## 세부 요약 - 주제별 정리

### 이안 버틀러의 벤치마크 결과는 현재 코딩 에이전트의 버그 탐지 한계를 명확히 보여줌

- 이안 버틀러는 Bismouth의 CEO로, Codeex와 유사한 종단형(End-to-End) 에이전틱 코딩 솔루션 개발을 주도함
- 수 개월에 걸쳐 여러 코드 에이전트의 버그 탐지 및 수정 능력을 벤치마크하고 평가함
- 벤치마크 결과를 최근 공개했으며, 주제는 "코딩 에이전트의 버그 탐지 효율성"임
- Devon, Cursor 등 유명 코드 에이전트를 비롯해 총 6종의 주요 에이전트가 비교 대상이 됨
- 테스트는 수백 건 이상의 버그 리포트, 총 100개가 넘는 리포지터리, 1,200+ 이슈 등을 포괄함
- 결론적으로 대다수 에이전트는 실제 버그 탐지율이 낮고 오탐이 압도적으로 많은 '나쁜 성과'를 보임

### 버그 탐지에서 높은 오탐률과 낮은 실탐률이 실무 활용성에 큰 장애로 작용함

- Devon, Cursor 등 인기 에이전트의 실제 버그 탐지(True Positive) 비율은 10% 미만
- 한 에이전트는 단일 작업(태스크)에서 70개의 버그 이슈를 보고하였으나, 모두 실제 버그가 아님(거짓 양성)
- Cursor는 100개가 넘는 리포지터리, 1,200개 이상의 이슈에서 무려 97%에 달하는 높은 오탐률을 기록함
- 실제 개발 현장에서 버그 탐지 에이전트를 사용할 경우, 지나친 경고로 인해 개발자가 알림(alert fatigue)에 시달리며 신뢰도가 저하됨
- 결국 신뢰 부족으로 에이전트의 제안을 무시하고, 미탐지 버그가 실제 프로덕션 환경까지 전달될 위험 존재

### 코딩 에이전트와 사이드 바이 사이드로 협업 시 반드시 구체적 룰 설정이 필요함

- 각 에이전트는 별도의 'rules' 파일(규칙 목록)을 지원하며, 여기에 구체적·스코프 지정형 지침을 입력해야 함
- 룰에는 보안 관련 이슈, 논리적 버그, 기타 중요한 점 등 상세 정보를 명시해야 함
- 사용자는 막연하게 '이 코드에서 버그를 찾아줘'가 아닌, 'off bypass, protocol pollution, SQL 인젝션 등 구체 유형을 점검하라'는 식으로 룰 작성 권장

### 맥락(Context) 관리 미흡이 주요 에이전트의 약점으로 드러남

- 대형 코드베이스에서 버그를 심어두면, 에이전트는 넓은 코드 영역을 탐색하고 특정 버그를 정확히 찾는 데 난항을 겪음
- 시간이 지나면 에이전트는 자신이 읽은 범위를 잊거나 논리적 연결고리가 약해져, 복합적·다단계 버그를 탐지하지 못함
- 특히, 맥락 윈도(context window)의 한계에 도달하면 요약(compaction)이 발생하고, 이 때 버그 탐지력이 크게 떨어짐
- 사용자(개발자)는 주기적으로 변경된 코드(diff)와 필수 파일을 에이전트에 명확히 제공, 맥락 손실을 최소화해야 함

### 사고 모델(Thinking Models)은 현존 모델 중 복잡한 버그 탐지 성능이 뛰어남

- 사고 모델은 코드 내 여러 고려사항을 논리 흐름을 타고 확장하며, 원인-결과 연결까지 추적 가능
- Thought trace(사고 추적)를 통해 얼마나 복합적 탐색이 이루어지는지 확인할 수 있음
- 벤치마크 전반에서 Non-thinking 모델 대비 어려운 위치의 버그를 더 자주 발견, 우수성을 입증함

### 룰 파일 작성 시, 보안 이슈와 테스트 요구 조건을 명확히 입력해야 성능이 향상됨

- 세계적으로 표준적인 보안 취약점 목록인 OWASP Top 10을 룰 파일에 포함시키는 전략이 유효함
- 구체적인 버그/보안 항목을 명시적으로 입력하면 에이전트가 이를 코드 검사 우선사항에 포함시킴
- 단순 탐색 명령보다 명확한 클래스/이슈 지정을 통해 모델의 버그 탐지 감도를 높일 수 있음
- 특히 '고쳐진 후 테스트 통과'를 요구하는 규칙을 명시해, 코드병합 전 자동 검증 단계 추가 가능

### 구조 파악과 인벤토리 작성이 맥락 이해도 및 버그 탐지력 향상에 직접적 효과

- 코드 내 클래스, 변수, 사용 패턴 등 구조를 인벤토리(목록화) 하도록 에이전트에 요청하는 것이 효율적임
- 이렇게 구조 정보를 먼저 인덱싱하면, 이 후 구체적 버그 탐지 요청 시 연관 검색이 용이해짐
- 실험 결과, 구조 인벤토리-버그 탐지 2단계가 단순 전체 탐색보다 실효성이 더 높은 것으로 확인

### 반복 실행 시에도 동일한 범위 전체를 포괄하지 못하는 근본적 한계가 존재함

- 여러 번 에이전트를 실행해도 탐지되는 버그 리스트가 매번 달라지는 높은 변동성 존재
- 이는 인간 개발자 수준의 전체 코드베이스 장악력이나 일관성 있는 진단이 현재 AI 모델에겐 부족함을 의미
- 단일 실행으로 전체 버그 맵핑이 되지 않아, 사용자는 완전한 커버리지를 위해 다수 반복 실행이 불가피함

### Bismouth 제품 및 벤치마크 결과를 통한 신뢰성 확보 방안이 소개됨

- Bismouth.sh는 버그 탐지 후 Pull Request(자동PR) 생성, GitHub/GitLab 등 플랫폼 연동, Jira/Linear 연동 등 실제 현장에서 사용 가능한 솔루션 제공
- 취약점 스캐닝, 코드 리뷰 자동화, 온프레미스(사내 서버) 배포 등 다양한 배포 옵션 소개
- 발표 내용의 벤치마크 전체 데이터셋과 평가 방법론, SM100 벤치마크 등 실측 자료의 QR코드 및 개별 링크 안내
- 누구나 벤치마크 상세 결과를 확인할 수 있도록 투명성 강조

### 실무적 가이드로 '구체 룰, 맥락관리, 사고 모델 활용'을 일관되게 강조함

- 코드 에이전트의 한계 극복을 위해, 사용자 주도하의 세밀한 룰 입력과 맥락정보 제공, 사고 모델 선택이 모두 병행돼야 함을 반복 언급
- 이러한 실천이 'vibe coding'(경험 기반 코딩 및 실시간 협업)에서 최상의 결과를 얻는 핵심 노하우로 제시됨
