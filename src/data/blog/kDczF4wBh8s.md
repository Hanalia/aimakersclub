---
author: AI Makers Club
pubDatetime: 2025-08-01T08:20:48.139Z
title: "From Self-driving to Autonomous Voice Agents - Brooke Hopkins, Coval"
slug: kDczF4wBh8s
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "이 영상은 Whimo(웨이모)에서 평가 시스템을 이끌었던 브룩 호프킨스(Coval 창업자)가 자율주행의 '대규모 시뮬레이션 평가' 경험을 음성 AI 에이전트 평가에 어떻게 적용할 "
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/kDczF4wBh8s/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [From Self-driving to Autonomous Voice Agents — Brooke Hopkins, Coval](https://www.youtube.com/watch?v=kDczF4wBh8s)  
**채널명:** AI Engineer

## *자율주행에서 음성 에이전트로 — 자율 음성 에이전트를 위한 평가 시스템 구축* 핵심 요약

- 이 영상은 Whimo(웨이모)에서 평가 시스템을 이끌었던 브룩 호프킨스(Coval 창업자)가 자율주행의 '대규모 시뮬레이션 평가' 경험을 음성 AI 에이전트 평가에 어떻게 적용할 수 있는지 심층적으로 설명함
- 음성 에이전트는 자동화에 대한 높은 기대(콜센터 등 완전 자동화)와 동시에 서비스 신뢰성에 대한 우려로 확산이 더디며, 실제 배포 및 생산 환경 확장에 어려움이 큼
- 전통적으로 두 가지 접근법(완전히 통제적인 IVR 방식 vs. 유연하지만 예측 불가한 AI 방식)이 있었으나, 브룩은 '신뢰성과 자율성의 동시 확보'가 가능하다고 주장
- 자율주행차는 초기에는 수작업 테스트와 개별적/명시적 시나리오 평가에 의존했으나, 이는 확장성 부족과 높은 유지관리 비용의 문제를 겪었음
- 이후 업계 전체는 '대규모 통계적 시뮬레이션 평가'로 진화하여, 실세계를 반영한 다양한 이벤트의 빈도·성공률 등을 측정하여 안정적인 시스템 개발에 성공함
- 이 경험을 차용해 음성 에이전트에도 다양한 상황을 자동화해 대규모로 평가(시뮬레이션→지표 산출→자동/수동 반복 피드백 순환)하는 전략이 핵심임을 강조
- LLM 기반 평가(LLM-as-a-judge)의 불확실성을 인간협업, 반복실험, 사용자 데이터 연동을 통해 극복하고, 실제 구현시 어떤 요소(음성/텍스트 수준, 현실성, 상황 적합성)에 집중해야 할지 예시와 함께 제시
- 최적의 평가 전략 수립법(공용 벤치마크→도메인별 자체 벤치마킹→모듈/태스크 단위 평가→엔드투엔드, 지속적 모니터링)과 구체적 운영방안(대시보드, 이슈관리 프로세스) 안내
- 앞으로 '음성'이 웹, 모바일 이후의 차세대 플랫폼이 될 것이며, 모든 기업이 필연적으로 음성 에이전트 도입이 필요해질 것으로 전망함
- Coval과 관련 제품/툴(Metric Studio 등)이 이 새로운 음성 생태계와 평가 자동화 흐름을 리드하고 있음을 간접적으로 언급

---

## 세부 요약 - 주제별 정리

### 음성 에이전트가 아직 광범위하게 확산되지 못하는 이유는 신뢰성 우려와 과대평가 및 과소평가의 공존 때문임

- 음성 에이전트는 실제로는 중요한 복잡한 워크플로우를 자동화할 수 있다는 약속을 지니고 있음
- 개발자들은 음성 에이전트의 잠재력을 알고 있으나 실제로 배포할 때는, 모든 콜 업무를 한 번에 자동화하려는 과도한 기대와 동시에 현재 기술의 현실적 한계를 간과함
- 10건의 대화에서는 성공해도, 이를 10,000~100,000건으로 확장하면 미세한 실패들이 누적되어 실제 서비스에서는 쉽게 신뢰를 잃게 됨
- 규모 확장 및 대고객 서비스로 넘어가는 과정이 매우 어렵고, 이로 인해 많은 기업들이 음성 AI 도입을 주저함

### 기존에는 통제와 자율성 사이의 선택이 불가피했으나, 자율주행 분야의 교훈은 신뢰성과 자율성을 동시에 추구할 수 있음을 시사함

- 전통적 방식: IVR 스타일로 음성 AI 흐름을 완전히 강제(DTMF 선택, 고정 답변)—예측 가능성은 높으나 유연성 떨어짐
- 완전한 자율형 방식: LLM 기반 자유 대화—새로운 상황에도 적응 가능하지만, 비예측성과 통제 어려움이 문제로 제기됨
- 브룩은 이 선택이 '가짜 양자택일'임을 지적하며, 자율주행은 대규모 시뮬레이션 평가를 통해 두 마리 토끼를 잡았다고 사례를 들어 설명

### 자율주행의 '대규모 시뮬레이션 평가' 도입과 그 효과는 음성 에이전트에도 직접 적용 가능함

- 웨이모 등 자율주행 업계는 초기에는 수동 테스트(실제 차량 테스트, 문제 발견 후 엔지니어와 반복)로 시작했으나, 확장성·유지관리 문제가 심각했음
- 이후 명확한 시나리오별 구체적 테스트(조건 명세 → 기대 동작 일치 여부 판단)로 전환했으나, 시나리오 노화·구축비 상승으로 역시 한계에 봉착
- 업계 전체가 대규모 통계 기반 시뮬레이션(수많은 케이스를 반복 생성/측정, 이벤트 빈도나 성공률 등 확률적 수치 산출)로 전이, 실제 런칭 전략도 이에 기반
- 자율주행의 이 평가 체계를 음성 에이전트에도 적용함으로써, 예상치 못한 실세계 상황 대응력과 신뢰도의 동시 확보가 가능함
- 두 분야가 실세계를 단계적 인터랙션(감지→반응→피드백) 방식으로 모델링한다는 점에서 시뮬레이션 기반 평가의 필요성과 적합성이 높음

### 음성 에이전트 평가에서 '한정 입력-출력 평가'가 아니라 '확률적·전반적 지표'로 발전해야 함

- 전통적인 LLM 평가 방식: 고정 입력에 대한 출력이 기준에 부합하는지 판단(골든 데이터셋 매칭)
- 음성 에이전트는 적용 시나리오가 더 다양하고 '참조 없는 평가'(Reference-free eval, 즉 정답대조 없는 전방위 통계 측정)가 더욱 중요함
- "사용자 질의 해결 빈도", "반복적 출력 비율", "부적절한 응답 빈도" 등, 특정 케이스가 아닌 전체적 지표 설계로 확장 강조
- 이러한 평가 전략이 실제 서비스 확장·운영 단계에서 유지관리와 품질관리를 자동화하는 데 필수임

### 지속적인 자동 평가 루프와 수동/자동의 결합이 지속 확장 및 운영 효율성의 핵심임

- 자율주행에서는 CI/CD에 준하는 presubmit/postsubmit 자동 평가 및 대규모 릴리즈 전/후 검증, 실시간 모니터링과 피드백 체계를 운용함
- 음성 에이전트도, 초기엔 시뮬레이션 대화(가상 시나리오 구성→자동 지표 측정)→제품화→실서비스 데이터→실패 케이스 탐지→수동 판단→반복 개선 순서로 순환적 평가가 이루어짐
- 모든 평가를 자동화하는 것이 목표가 아니라, 평가 자동화로 확보한 시간·에너지를 '인간의 복잡한 판단이 필요한 부분'에 집중하는 것이 전략임

### 평가에 필요한 현실성(Realism) 수준은 테스트 목표에 따라 달라지며, 비용 대비 효과를 고려한 시뮬레이션 설계가 관건임

- 주어진 테스크별로 어떤 수준의 현실성이 필요한지가 구체적으로 다름
    - 워크플로우, 기능성, 인스트럭션 팔로우 등은 텍스트 기반 시뮬레이션(목적성 측정)에 집중 시 충분
    - 인트로럽션(중간 개입), 지연시간(Latency), 기본 음성 품질은 실제 음성만으로도 적합
    - 억양, 잡음, 다양한 사투리 등 고품질 현실성은 실제 배포나 특정 이슈 재현 시에만 필요
- "하이퍼리얼리즘"만을 무작정 지향하기보다, 필요한 변수·지표에 따라 시뮬레이션 복잡도를 결정해야 함

### 반복 실험과 다수의 시나리오 재실행(denoising, 확률적 분석)은 신뢰도 확보와 품질지표 설정에 중요함

- 개별 시나리오 실패 사례가 발견될 때, 한 번의 실패는 큰 문제가 아님
- 재시뮬레이션(동일 시나리오 수차례 반복, 예: 100번 반복→몇 번 실패하는지) 통해 확률적 실패율 추정
- SLA(Service Level Agreement)처럼 제품 요구 신뢰도(가령, 99% 성공률)를 정의하고, 각 기능/시나리오별로 '몇 시그마(9s)의 신뢰도'가 필요한지 고려
- 동 분야 자체의 불확실성(특히 LLM 기반에서의 응답 다양성)을 계량적으로 파악하고 관리하는 절차가 필수임

### 음성 에이전트 평가 전략은 제품의 가치 정의 및 실제 운영 기준과 밀접하게 연동되어야 함

- 평가지표 설계는 "내 제품이 잘해야 할 것/덜 중요하게 여길 것"을 명확히 정의하는 과정임
- 범용 음성모델(OpenAI API 등)은 이미 출시되어 있으나, 실제 기업들은 특정 영역(예: 의료, 보험, 세일즈 등)에 집중하여 각자 맞춤형 평가기준이 필수
- 응답 속도(Outbound 세일즈: 짧아야 함, 환불창구: 상대적으로 덜 민감), 인터럽션 대응, 인스트럭션 정확도(예약 업무 등)가 어플리케이션마다 중요도가 다름
- LLM을 평가자로 쓸 때(LLM as a judge), 개별 대화 성패 기준 등은 노이즈가 많아 다수 반복·인간 피드백 연계 필요

### Coval의 Metric Studio는 인간 피드백과 반복적 계량화를 통한 지표 신뢰도 제고를 지원하며 대규모 평가 자동화를 현실화함

- Metric Studio: 인간 피드백과 자동 지표 간 일치율이 높아질 때까지 반복적으로 튜닝할 수 있게 해줌
- 수작업 레이블(labeling)과 반복 시뮬레이션으로, 자동화된 메트릭의 신뢰도를 점진적으로 개선
- 신뢰 수준 확보 후, 수천~수만 건의 대화에 자동 적용 가능

### 최적의 문맥별 음성 평가 프로세스는 벤치마킹→도메인 특화→태스크별 모듈 평가→엔드투엔드→지속적 모니터링/대시보드 구축의 순환 구조로 운영되어야 함

- 공용 벤치마크(VoiceBench 등) 활용: 대략적 성능 방향성 확인 가능
- 자체 도메인별 벤치마킹: 실제 도메인(의료, 법률 등)에 맞는 데이터/용어로 자체 평가
- 태스크 모듈별(예: ASR, TTS, LLM 등 각 스택별 성능) 세부 벤치마킹 필수—서로 다른 LLM/보이스 선택, 개별 모델 비교
- 엔드투엔드 평가로 심각한 문제가 없는지 전반 확인 후, 실서비스 중 발견된 문제는 즉시 평가군에 추가(이슈 관리, 테스트셋 차등 관리)
- 모니터링/대시보드화로 연속적인 현황 체크 및 문제 사후 관리(파일럿 고객별, 워크플로우별 등 다양하게 맞춤화)

### 앞으로 '음성'이 새로운 실질적 플랫폼이 되어, 모든 기업에 음성에이전트가 기본 서비스로 자리잡을 것임

- 웹→모바일에 이어 '음성 경험'이 본격적인 차세대 플랫폼 변화를 이끌 것으로 예상
- 앞으로 3년 내에 모든 기업이 음성 에이전트를 도입하지 않으면 모바일앱이 없는 기업처럼 비효율적으로 인식될 것이라 전망
- 사용자 기대치는 급격히 높아질 예정—'마법 같은' 자연스러운 음성 인터페이스가 표준이 됨
- Coval은 이런 변화 흐름의 중심에서 차세대 평가 및 개발 인프라(프로세스, Metric Studio, 벤치마크 툴 등)를 제공하며 관련 인재를 적극 채용 중임

### 음성 AI 생태계는 다양한 문제, 확장성, 인프라 구축 등에서 신기술의 '전장'이자, 열려있는 개척지임을 강조하며 마무리

- 음성 AI는 다양한 모델, 복잡한 스택, 전방위의 문제를 다뤄야 하는 이 분야 특성상 기술·비즈니스 양면에서 미지의 영역이 많음
- Coval(브루크와 팀)은 이러한 '답 없는' 도전 영역에서 미래를 주도할 인재, 기술, 프로세스 구축에 깊은 흥미와 확신을 보임
