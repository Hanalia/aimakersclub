---
author: AI Makers Club
pubDatetime: 2025-07-17T08:19:59.772Z
title: "Netflix's Big Bet: One model to rule recommendations: Yesu Feng, Netflix"
slug: AbZ4IYGbfpQ
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "이 영상은 넷플릭스가 추천 시스템의 모든 유즈케이스를 하나의 파운데이션 모델로 통합하는 전략을 중점적으로 다룸 넷플릭스의 홈, 검색, 키즈, 모바일 등 다양한 추천 화면과 늘어나는"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/AbZ4IYGbfpQ/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [Netflix's Big Bet: One model to rule recommendations: Yesu Feng, Netflix](https://www.youtube.com/watch?v=AbZ4IYGbfpQ)  
**채널명:** AI Engineer

## *넷플릭스의 대형 도전: 추천을 위한 단일 모델 전략* 핵심 요약

- 이 영상은 넷플릭스가 추천 시스템의 모든 유즈케이스를 하나의 파운데이션 모델로 통합하는 전략을 중점적으로 다룸
- 넷플릭스의 홈, 검색, 키즈, 모바일 등 다양한 추천 화면과 늘어나는 콘텐츠(영화, TV, 게임, 라이브 등) 때문에 복잡성이 높아짐
- 과거엔 행(row), 아이템, 시청 이력 등 목적에 따라 각각 별도 모델을 개발했고, 이로 인한 중복 및 비효율(레이블 및 피처 엔지니어링)이 발생
- 여러 파편화된 모델은 운영과 혁신 속도를 저하시킴: 재사용이 낮고, 새로운 케이스마다 모델을 새로 만들어야 하는 부담
- 4년 전 COVID-19 기간경, 사용자 표현(유저 임베딩) 학습의 중앙화 및 트랜스포머 기반 파운데이션 모델 도입 결정
- 핵심 가설은 (1) 대규모 세미 슈퍼바이즈드 러닝으로 개인화 질이 올라간다, (2) 파운데이션 모델은 전사적으로 높은 레버리지를 줄 수 있다는 것
- 데이터 전처리·토크나이제이션, 이벤트 임베딩, 트랜스포머 계층, 복수 타깃 예측 등 LLM(대형 언어 모델)의 노하우를 대거 참조·도입
- 다양한 응용 방식(하위 그래프 삽입, 임베딩 배포, 파인튜닝/디스틸 등)으로 기존과 달라진 시스템 통합 구조를 설명
- 실제 적용 1.5년 동안 다양한 추천/개인화 AB테스트에서 일관된 개선 효과와 인프라 통합 효과를 달성
- 향후 목표는 다양한 엔터티(영상, 게임 등)를 포괄할 범용 표현, 생성적 추천, 프로프트 튜닝 방식 적응 가속 등으로 요약

---

## 세부 요약 - 주제별 정리

### 넷플릭스 홈과 추천 도메인의 복잡성은 3중 구조로 인해 극대화됨
- 넷플릭스 홈(2D 행·아이템 레이아웃)에는 여러 차원에서 다양성이 존재
- ① 행(row): 장르별, 트렌드별, 오리지널, 신작 등 다양한 기준의 추천 행이 존재
- ② 아이템(entities): 영화•TV시리즈뿐 아니라 게임, 라이브 스트리밍 등 콘텐츠 타입 확대 중
- ③ 페이지: 홈, 검색, 키즈용, 모바일 피드(선형 레이아웃) 등 목적별로 UX와 추천 방식이 상이
- 이 세 가지 축의 결합으로 매우 다양한 추천 유즈케이스가 생김

### 과거의 파편화된 모델 구조는 데이터 및 운영 중복을 가중시켰음  
- 목적별로 영상을 랭킹하는 모델, 행을 랭킹하는 모델 등 독립적으로 개발
- 예를 들어, 시청하지 않은 작품 추천과 이미 소진한 콘텐츠 위주 추천이 별도로 존재
- 데이터 라벨링, 피처 엔지니어링 과정이 각각 이루어져 중복과 변형이 누적
- 동일한 기반 데이터(예: 시청 이력)로 각기 다른 피처가 개발되어 비슷하지만 미세하게 변형된 형태가 다수 생성
- 유지·보수, 기능 확장, 혁신 속도가 줄어드는 한계점 직면

### 추천 시스템 혁신의 핵심질문: 중앙화된 학습이 가능한가?  
- 콘텐츠/비즈니스 케이스가 계속 확장됨에 따라 개별 모델 체계는 확장성에 한계
- 기존 구조는 데이터/피처 일부만 공유했으며, 대부분 모델을 새로 시작해야 했음
- 혁신 속도를 높이기 위한 중앙화 방안 모색: 유저 임베딩 학습의 단일화

### 트랜스포머 기반 파운데이션 모델 도입과 두 가지 핵심 가설의 수립
- 2020~2021년 팬데믹 시기, 트랜스포머 구조 LLM의 성공 노하우를 추천 도메인에 적용하기로 결정
- 가설1: 대규모 데이터 기반 세미 슈퍼바이즈드 러닝은 개인화 품질을 지속적으로 강화할 수 있음(스케일링 법칙 적용)
- 가설2: 파운데이션 모델을 인프라 전반에 통합해 다운스트림 모델 성능과 개발 효율 동시 개선 가능

### 데이터 가공과 토크나이제이션에서 LLM과의 유사점과 차별점을 적용함
- LLM처럼 데이터 클리닝 및 토크나이제이션(토큰 설계)이 품질에 지대한 영향
- 추천에서는 “언어 토큰” 대신 “이벤트 토큰(시청/상호작용 이벤트)”을 활용
- 이벤트 토큰은 시간, 위치, 디바이스, 행(row), 페이지 등 풍부한 필드를 포함(복수 필드 설계가 중요)
- 토크나이제이션의 그레뉼러리티(세분화 정도)와 컨텍스트 윈도우(문맥 길이) 사이 트레이드오프 존재
- 프리트레이닝과 파인튜닝 목적에 맞춰 유연하게 토크나이제이션 방식 조정

### 임베딩, 트랜스포머, 목적함수 설계에서 추천 도메인의 특수성이 반영됨
- 이벤트 임베딩에서 “ID 임베딩”과 “의미 기반 콘텐츠 정보(semantic content)”를 혼합하여 코스타 문제(신규 콘텐츠 임베딩 문제) 대응
- LLM은 언어범주 내 새로운 토큰 처리가 강점이나, 추천 도메인은 신규 엔터티(예: 신작 영상)에 약점이 있어 보강이 필요
- 트랜스포머 계층의 은닉 상태를 추출해 장기적·안정적인 유저 표현(user representation) 구축
- 유저 프로필 변화에 따른 표현 안정성, 시퀀스 및 계층별 집계 전략 등 구현 고민
- Loss function(목적함수)은 LLM보다 훨씬 풍부: 예를 들어, 다음 소비 엔티티 예측, 액션 타입, 메타데이터(장르 등), 시청 시간 등 다수의 타깃 필드로 다중/계층적 학습 가능

### 스케일업 시 성능 개선은 ‘스케일링 법칙’에 따라 지속적임이 확인됨
- 2년여간 프로파일 수(수천만~1억 단위) 및 파라미터 수(10M~1B)까지 확장하며 꾸준한 성능 개선 관찰
- 추천 시스템은 LLM 대비 지연(latency)·비용에 매우 민감하므로 대형화-경량화(디스틸 등) 병행 필요

### 대형 언어 모델(LLM)에서 도입한 세 가지 중요 기술이 추천 도메인에 적합했음
- Top-multi-token prediction: 단일 토큰 예측보다 여러 토큰을 동시에 예측해 장기적 회원 만족 지향 및 시간 변화에 강건한 모델 구현 → 실제 메트릭(지표) 향상
- Multi-layer representation: 다층(트랜스포머 각 계층) 표현을 활용해 더욱 정교하고 안정적인 유저 임베딩 확보(Layer-wise supervision, Self-distillation 등)
- Long-context window: 컨텍스트 윈도우의 확장, Sparse attention, 슬라이딩 윈도우 등으로 장기 시퀀스처리 및 트레이닝 효율 극대화

### 파운데이션 모델 도입 이후 모델과 임베딩 활용 방식이 크게 진화함  
- 파운데이션 모델(FM)이 도입되기 전엔 분석-특징-모델이 모두 별도로 관리됨
- FM 이후 데이터, 유저 및 콘텐츠 임베딩은 공통 계층으로 통합, 개별 응용모델은 FM 위에 “얇은 레이어”만 얹는 구조로 단순화
- 응용 방식:
    - ① FM을 하위 그래프(subgraph)로 다운스트림 모델에 통합
    - ② 임베딩을 임베딩 스토어로 실시간 배포, 다양한 응용/분석 모델이 직접 활용
    - ③ 파인튜닝/디스틸 등 특정 어플리케이션 특화 버전 제공 (온라인 서빙 지연 등 실전적 요구 반영)
- 임베딩 갱신 주기, 안정성 등도 실제 시스템 운영에서 주요 고려점

### 파운데이션 모델(system FM)은 실제로 성능 및 인프라 효율을 증명함
- 지난 1.5년 간 FM을 적용한 응용(앱) 수, FM 기반 AB테스트 성공(‘win’) 수치가 계속 증가(BAR 그래프 지표)
- 추천 품질, 개발/실험 속도 모두 크게 향상(신규 앱이 바로 FM을 미세적합하여 론칭 가능)
- 인프라 통합 및 운영 비용 절감 효과도 큰 것으로 나타남

### 확장 가능성을 위한 세 가지 차세대 방향성과 연구 과제를 언급함
- ① 다양한 엔터티(게임, 비디오 등)를 모두 포괄하는 범용 임베딩(semantic ID, universal representation) 확립
- ② 생성적 추천(Generative retrieval): 단일 콘텐츠가 아닌 컬렉션/리스트 추천 및 다단계 디코딩에 생성형 기법 적용
- ③ 프롬프트 튜닝을 통한 빠른 적응: LLM의 소프트토큰 개념처럼 프롬프트 조절로 FM이 다양한 응용 요구에 유연히 대응할 수 있도록 연구 진행

### 질의응답: 그래프/강화학습/임베딩 등 기술적 추가 논의와 도입 현황  
- 그래프 모델: 넷플릭스는 엔터테인먼트 지식 그래프를 구축해 그래프 임베딩을 추천, 쿼리 등 다양한 목적으로 활용 중
- 강화 학습: 사용자 행동 히스토리가 스파스(드문)하게 보상 정보로 활용됨, 컬렉션 생성 등에서 보상이 가이드 역할
- 임베딩 활용: 모델에서 학습된 통합 임베딩은 다운스트림 모델에 직접 주입 및 활용 가능(상위–하위, 즉 Upstream–Downstream으로 구조 설계)
- 영상 임베딩: 현재는 주로 메타데이터 기반이지만, 프레임 단위(클립 단위 등) 임베딩 연구도 사내 별도 조직에서 진행 중이며, 앞으로 더욱 세분화된 콘텐츠 표현 계획
