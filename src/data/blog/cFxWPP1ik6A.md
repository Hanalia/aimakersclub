---
author: AI Makers Club
pubDatetime: 2025-07-28T08:18:33.056Z
title: "Government Agents: AI Agents vs Tough Regulations - Mark Myshatyn, Los Alamos National Laboratory"
slug: cFxWPP1ik6A
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "**본 영상은 Los Alamos 국립연구소(미국의 핵심 핵과학 연구기관)의 AI 아키텍트 Mark Myshatyn이 정부 기관 내에서 AI 에이전트의 도입과 그에 따른 강력한 규"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/cFxWPP1ik6A/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [Government Agents: AI Agents vs Tough Regulations — Mark Myshatyn, Los Alamos National Laboratory](https://www.youtube.com/watch?v=cFxWPP1ik6A)  
**채널명:** AI Engineer

## *정부 기관: AI 에이전트 vs 강력한 규제* 핵심 요약

- **본 영상은 Los Alamos 국립연구소(미국의 핵심 핵과학 연구기관)의 AI 아키텍트 Mark Myshatyn이 정부 기관 내에서 AI 에이전트의 도입과 그에 따른 강력한 규제 및 거버넌스의 도전 과제를 소개하는 강연임**
- **Los Alamos 연구소는 70여 년간 통계·머신러닝을 적용해왔으며, 현재는 AI 에이전트의 활용으로 연구·국가안보 임무를 혁신하고자 함**
- **실제 예시로, 생성형 AI 및 에이전트 기반 시스템을 이용하여 핵융합 캡슐(ICF capsule) 설계를 자동화 및 최적화함—AI가 논문을 읽고 가설을 세운 뒤, 초고성능 컴퓨터에서 직접 물리 시뮬레이션을 실행**
- **국가안보 AI팀은 빠른 연구와 자체 모델 개발을 추구하나, 상업/학계/프런티어랩과의 폭넓은 협력이 필수적이라 강조**
- **연구소는 Nvidia, HPE와의 협력으로 2,500여 노드의 초고성능 슈퍼컴퓨터(Venado)를 구축, OpenAI 등 최신 모델들을 기밀 환경에서 실험 중임**
- **최근 OM(Office of Management) 메모랜덤 M-25-21, M-25-22(2024년 4월 발표)가 연방정부의 AI 도입·거버넌스 원칙을 공식화함—안전하고 신속한 도입과 실질적 책임, 위험구분(고위험/저위험) 등 규정**
- **정부·연구소 데이터 및 미션 특성상 극도의 정보보안이 요구—FedRamp, NIST 853, DoD SRG, CNSI 1253 등 수백~천 개 보안통제 기준이 적용됨**
- **AI 거버넌스·규제 프레임워크는 현재도 설계·시행 중(180일 로드맵), 실무·기술·법률 측면에서 "새로운 종이 한 장"처럼 유연성과 협업의 기회가 큼**
- **정부기관과 AI 개발사의 신뢰·책임 구조, 데이터 거버넌스, 소프트웨어 구조(설명력, 격리성, 이식성, 거버넌스 지원, 신속성) 마련이 필수**
- **Los Alamos 연구소는 "함께 미래를 만들어가는 파트너십"을 강조하며, 미국의 국익·과학기술 발전을 위한 민관 협업, 개방적 접근을 독려함**

---

## 세부 요약 - 주제별 정리

### Los Alamos 연구소는 70년 넘게 머신러닝을 실무에 적용해왔으며, AI의 에이전트적 전환에 적극 대응함

- Los Alamos 국립연구소(LANL)는 인공지능·머신러닝(ML)을 약 70년간 실무에 적용, 그 뿌리가 1950년대까지 거슬러 올라감
- 1956년 촬영된 사진(Maniac 1 슈퍼컴퓨터 앞) 속에서 체스(비숍 제외)가 시연—당시 메모리 부족 탓에 전체 체스판도 인코딩 불가
- 체스 실험은 통계/알고리즘 기반의 자동화 문제 해결 연구의 초기 사례로, 맨해튼 프로젝트 이후 몬테카를로 기법 등 개발에 사용됨
- 이러한 역사적 배경 덕분에 Los Alamos 연구진은 AI 혁신과 에이전트적 접근(automated agentic approach)이 크게 새롭진 않으나, 새로운 기회의 폭이 훨씬 커졌다고 강조

### 에이전트형 AI 시스템을 활용해 과학적 문제 해결을 자동화·고도화함

- 단순한 생성 모델(예: 챗봇) 수준이 아닌, AI에 논문 읽기·탐색·가설 생성·코드 작성·슈퍼컴퓨터에서의 시뮬레이션까지 실질적 자동화 수행
- 구체적 시연 예시: ICF(관성밀폐핵융합) 캡슐 설계 미션에서, AI가 관련 논문을 여러 편 읽고 유의미한 가설을 개진한 뒤, 하이드로다이내믹·열역학 시뮬레이션을 수행해 최적 설계 산출
- LLM 자체만으로 처리하는 것이 아니라, 연구소가 수십년에 걸쳐 축적한 수학·물리학 모델 및 안전관리/핵처리 경험까지 통합적으로 작동
- 이런 방식은 미션 수행 속도·품질을 개선하나, 동시에 위험 역시 가속화될 수 있음을 언급

### Los Alamos 연구소의 조직 규모와 AI 적용 범위는 매우 방대함

- 연구소 전체 영역만 약 40제곱마일, 실험실·테스트 시설·13곳의 핵시설 등 대규모 인프라 보유
- 근무 연구원 수만 약 2만 명, 엔터프라이즈 규모의 미션에서 인공지능 도입을 전사적으로 추진 중
- AI/GenAI 도입은 국방안보, 연구 자동화, 사이버보안, 조달, 급여 등 다양한 실질 업무 혁신으로 이어짐

### 자체 모델 개발과 외부 협력이 동시다발적으로 이루어지며, 공개/최첨단 모델 모두 연구에 활용함

- 상용 툴·오픈소스 도구 소비를 넘어서 연구소 자체 개발(모델, 시스템) 병행
- 한계 인식 및 개방적 태도—상업계/학계/프론티어 랩(예: OpenAI)과 파트너십 적극 추진
- 2024년 기준, UC 시스템(University of California)과 AI 미래기술 협력 발표
- OpenAI와 협력(Chem. Bio. Safety 업무), Nvidia 및 HPE와 Venado 슈퍼컴퓨터(2,500 노드) 공동 구축
- OpenAI 모델들을 내부 기밀망에 도입, 국가 기밀 데이터 및 미션에 특화된 실험 전개

### 정부·연구기관의 AI 적용에는 ‘책임·신뢰’가 더욱 중요하게 요구됨

- 프런티어 랩, 상용 SaaS, 정부기관 간 신뢰 구축이 핵심—특히 고위험, 기밀 데이터(핵물리 등) 위임 시 개발사에 높은 책임 부과
- “FedRamp(연방정부 클라우드 보안 인증), NIST 853(1,000개 이상 보안통제), DoD SRG 등 엄격한 보안·거버넌스 기준을 충족해야 함”
- 기밀 데이터의 특성상 물리학적/운영적 정보, PII, 미션 데이터 유출 시 지리정치적, 군사적 위험 및 실제 인명 피해 발생 가능
- 정부기관 입장에서는 신뢰할 수 있는 파트너(개발사, 클라우드 제공사, 툴 빌더)와만 협력할 준비가 되어 있음—적합하지 않으면 즉시 협력 거절

### 2024년 4월 OM 메모랜덤(M-25-21 등)이 연방 AI 도입의 거버넌스 원칙을 공식화함

- 행정부 교체로 과거 행정명령이 대체되고, 최근 OM 메모(M-25-21, M-25-22)가 발표(2024.4)
- 주요 내용: 연방기관은 AI를 빠르게 도입하되, 모든 도입과정에서 엄격한 평가 및 책임 소재 명확화 필수
- 실제 미션 임무에서 AI 활용 시 “책임/추적성/위험 구분(고위험/저위험)/파일럿 관리” 등 세부 실행안 마련 필요
- 단순 사무 도구 수준의 AI 적용에 그치지 말고, 각 기관 주요 미션에 AI를 내재화할 것 권고

### 보안·컴플라이언스 체계는 현존 최고 수준의 엄격함을 요구하고, 클라우드/SaaS 개발사는 이를 수용 능력이 중요함

- FedRamp: 200~400개 보안통제를 서드파티(제3자) 평가 및 지속관리가 핵심—한 번 인증에 드는 비용·수고가 큼
- DoD(국방부): FedRamp 3단계 보안 등급에 더해 2개 추가(impact level), DoD SRG·CNSI 1253 등 더 폭넓은 규제 적용
- 연구소가 도입할 수 있는 툴·서비스 범위는 보안 송수신이 충족된 소수 클라우드/오픈소스에 한정—문턱이 매우 높음
- 서비스 공급(벤더)은 DoD impact level 5 환경에 맞춰 소프트웨어 설계 시, 어디든 배포 가능한 높은 이식성 확보

### 현재 AI의 거버넌스는 아직도 변화·진화 중이며, 민관 ‘공동설계’의 기회가 큼

- 2024년 OM 메모 기준, 향후 180일간 각 연방기관/연구소는 자체 AI 도입 전략, 위험관리, 규제계획 마련·시행 예정
- NIST(미국표준기술원) AI 위험관리 프레임워크(2023) 활용 권고
- 실제 거버넌스의 상세 규칙·법률·산출물 양식 등은 아직 다양한 해석 가능, 민간-정부 “룰 공동 개발” 기회 존재
- 법률·증빙 서류처리가 필연적이나, 기존 대비 개방성·효율성·유연성 제고 가능성 강조

### Los Alamos 연구소의 AI 협력 제안 및 기술적 요구 사항(설명력, 격리성, 이식성, 거버넌스 대응, 신속성)

- 엔터프라이즈/연방 대상 에이전트형 서비스 구축 시 4대 원칙 강조:
    - **설명력**: 시스템 의사결정 과정의 투명성, 문제 발생 원인 소명 능력(자체 전담조직의 책임성 강화)
    - **격리성**: SaaS/클라우드 시스템의 보안·네트워크격리(오픈소스 모델/도구 중점, 하이퍼스케일 클라우드 대체 방안 필수)
    - **이식성**: DoD Impact Level 5 환경 등 최소 서비스세트로도 정상 동작해야 범용성·확장성 확보
    - **거버넌스 대응력**: 오픈소스 의존성, 패치 전략, 소프트웨어 빌드 내역(SBOM) 등 서류화·분석·고객요구 충족
    - **신속성**: 정부 환경에서 서비스 출시/업데이트 지연(최대 수년간) 지양—수출통제 등 규정 때문에 높은 신속성이 더 중요
- 연방기관은 "미국 시민, 국가이익, 미션의 성취"에 책임을 지므로, 궁극적으로 신뢰 가능한 파트너만 선호

### Los Alamos는 미래 과학혁신과 국익 수호를 위한 민관 과감한 협력을 촉구함

- Los Alamos 연구소는 “최적의 수학·과학 응용은 세상을 하루아침에 바꾼다”는 창립 이념에 따라 혁신 지속
- AI 도구·에이전트·최첨단 모델 등은 국가안보와 함께, 인간 능력의 확장과 미래 변화의 ‘최고 기회이자 위협’—도전이 아닌 기회로 접근
- 고도의 핵비확산·감지(예: Mars Rover에 탑재된 ChemCam 등) 같은 미션 경험, 쌓인 데이터(수 PB급) 보유
- 단독 혁신 불가, 다양한 민간·학계 파트너십 개방—모두가 협력해 미지의 영역을 개척해야 함
- 기존 핵/연방 업무 너머, 기초과학·첨단소재·물리/생명/화학·고성능컴퓨팅 등 여러 미래 분야에도 같이 기여 가능함
