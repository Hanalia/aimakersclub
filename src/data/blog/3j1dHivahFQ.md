---
author: AI Makers Club
pubDatetime: 2025-05-02T04:34:44.491Z
title: How to Build Your Own AI Data Center in 2025 — Paul Gilbert, Arista Networks
slug: 3j1dHivahFQ
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: ## *2025년에 나만의 AI 데이터센터 구축하기 - Paul Gilbert, Arista Networks* 핵심 요약 - 엔터프라이즈용 AI 데이터센터 네트워크를 구축하는 방식
---

## *2025년에 나만의 AI 데이터센터 구축하기 - Paul Gilbert, Arista Networks* 핵심 요약

- 엔터프라이즈용 AI 데이터센터 네트워크를 구축하는 방식과 필요한 최신 인프라 특성을 상세히 설명
- 모델 훈련과 추론에 필요한 네트워크 구조, GPU와 스위치 연결 방식 등 실제 하드웨어 설계 사례 소개
- AI 모델, 특히 LLM 및 차세대 모델의 부하 특성과 네트워크 설계상의 과제(트래픽, 네트워크 고립성, 오버서브스크립션 금지 등) 설명
- 고성능 GPU(예: H100) 서버당 최대 9.6TB에 달하는 대용량 트래픽 처리에 대한 네트워킹 신기술 및 운영 경험 공유
- eBGP/iBGP와 RDMA, RoCE V2 등 네트워크 프로토콜 적용 이유와 적합한 트래픽 부하 균형 방법 안내
- 전력 소모, 쿨링 방식(수냉 냉각), 새로운 랙 디자인 등 데이터센터 설계의 현실적 어려움 및 변화 언급
- 인프라 모니터링·관리(텔레메트리, AI 에이전트 연동, 장애 감지 도구)와 네트워크 업그레이드 방식 등 실제 운영 노하우 제시
- Ultra Ethernet Consortium 및 향후 네트워크 기술 변화 예고와 대규모 AI 클러스터 설계 사례로 결론

---

## 세부 요약 - 주제별 정리

### AI 데이터센터의 네트워크는 완전히 분리되어 고성능 GPU만을 위해 설계됨

- AI 네트워크는 기존 데이터센터 네트워크와 달리 GPU 리소스 전용의 완전 분리형으로 구축됨
- GPU 서버마다 고속 스위치(리프·스파인 탑)로 연결, 타 용도(일반 트래픽)와의 혼선을 원천 차단
- 8개 GPU가 탑재된 서버와 400/800Gbps급 스위치로 수십~수백대 GPU를 간단하고 확장성 있게 연결함
- 백엔드 네트워크(훈련용)와 프론트엔드 네트워크(스토리지·데이터용)로 역할 특화

### 대규모 AI 워크로드는 네트워크 트래픽 폭증과 동시 ‘버스트성’ 트래픽으로 설계 난이도가 높아짐

- 모델 훈련·추론 시 모든 GPU가 동기적으로 대량의 데이터를 송수신→네트워크 트래픽이 ‘버스트’ 형태로 폭발
- 800Gbps 지원, 서버당 9.6TB 트래픽 등 기존 기업 데이터센터와는 차원이 다름
- 오버서브스크립션(핑거)” 없이 1:1 연결로 네트워크 용량을 견고하게 설계해야 함
- 트래픽 부하 분산과 패킷 손실 방지가 운영 안정성 확보에 핵심

### RDMA, RoCE V2, eBGP 등 특화 네트워크 기술과 트래픽 분산 전략이 필수로 적용됨

- 낮은 지연과 무손실 전송을 위해 RDMA 및 RoCE(RDMA over Converged Ethernet) V2 프로토콜 활용
- 트래픽이 한쪽 링크에 몰리지 않도록 패킷 수준이 아닌 ‘밴드위스 기반’(Cluster Load Balancing)으로 분산
- eBGP, iBGP 등 간단하면서 신속한 라우팅 프로토콜 선호
- congestion control(ECN, PFC 등) 및 버퍼 조정으로 동기화된 GPU 트래픽의 큐/병목 발생 예방

### 전력과 쿨링, 랙 구조 등 하드웨어·인프라 환경도 AI 중심으로 재설계 요구

- AI 서버(특히 8 GPU 탑재)는 1대당 약 10.2kW 전력 소모, 기존 랙·전력 라인 불가
- 구글, 엔비디아, 대형 기업들 중심으로 100~200kW 수냉식 랙 도입이 새 표준으로 대두
- GPU 장애, 대규모 케이블 문제 등 대수와 규모가 커짐에 따라 운영상 신경 써야 할 요소가 급증

### AI 모델의 특성과 작업 방식 차이로 인해 네트워크 장애가 전체 작업 중단으로 직결됨

- 기존 웹/DB는 일부 장애 시 회피·장애복구가 쉽지만, AI GPU 네트워크는 하나만 장애가 나도 전체 작업 실패 가능
- 트래픽 패턴도 동기식(east-west, GPU↔GPU)과 일반식(north-south, GPU↔Storage) 병존
- 네트워크 장애 감지·원인 추적의 중요성이 급증

### 네트워크 관리와 운영은 실시간 텔레메트리·에이전트 연동·스마트 업그레이드가 핵심으로 부상함

- 스위치-서버-스위치 간 구성정보, RDMA 에러, 패킷·트래픽 이상 정보를 실시간 집계·분석
- GPU에 직접 설치하는 AI 에이전트와 스위치 연동으로 GPU와 네트워크 상태 상호 확인 가능
- 스위치 소프트웨어 업그레이드 중에도 네트워크를 멈추지 않고 운영 지속(스마트 업그레이드) 가능

### 2025년 이후에는 Ultra Ethernet Consortium 등 차세대 네트워크 기술이 도입될 전망임

- 이더넷 800Gbps/1.6Tbps 등 고속화, 네트워크 처리를 NIC 장비에서 직접 수행하는 구조 예상
- Ultra Ethernet Consortium v1.0은 2025년 Q1 공개 예상, 대형 클라우드(AWS, 구글 등) 전면 도입 가능성
- 대규모 AI 클러스터(4,096 GPU, 576 800G GPU 등) 구축시 최신 박스(Arista 7800 시리즈 등) 활용 예시

---
