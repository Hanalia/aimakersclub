---
author: AI Makers Club
pubDatetime: 2025-08-09T23:44:58.223Z
title: "The Future of Evals - Ankur Goyal, Braintrust"
slug: MC55hdWLq4o
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "이 영상은 Ankur Goyal이 Braintrust에서의 지난 2년간 '평가(Eval)' 분야에서의 경험, 현재 상황, 그리고 향후 전망에 대해 발표한 세션임. Braintrus"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/MC55hdWLq4o/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [The Future of Evals - Ankur Goyal, Braintrust](https://www.youtube.com/watch?v=MC55hdWLq4o)  
**채널명:** AI Engineer

## *평가(Eval)의 미래 - Ankur Goyal, Braintrust* 핵심 요약

- 이 영상은 Ankur Goyal이 Braintrust에서의 지난 2년간 '평가(Eval)' 분야에서의 경험, 현재 상황, 그리고 향후 전망에 대해 발표한 세션임.
- Braintrust는 여러 조직이 AI 제품을 만들 때 핵심적으로 '평가'를 사용한다고 강조하며, 평균 고객사가 하루 13건, 많은 고객사는 하루 3,000건 이상의 평가를 실행하고 있다고 설명함.
- 선도적인 고객사는 하루 2시간 이상을 평가 작업에 할애하는 등, 평가가 AI 품질 개선의 핵심 수단임을 수치로 제시함.
- 기존 평가(Eval) 프로세스는 대부분 수동적으로 대시보드를 확인하고, 그 결과를 바탕으로 코드나 프롬프트, 데이터셋을 직접 수정해야 한다고 지적함.
- 최근 Braintrust에서 개발한 'Loop'란 에이전트를 소개하며, 이 도구를 통해 평가 과정의 자동화 및 효율화를 실현하고자 함을 밝힘.
- 'Loop'는 Claude 4와 같은 최신 프론티어 모델의 등장으로 가능해졌으며, 이전 모델 대비 최대 6배 뛰어난 성능을 보여줌.
- Loop는 프롬프트, 데이터셋, 채점 기준(Scorer) 제안 및 자동 최적화를 지원하며, 사용자 UI 내에서 편리하게 그 결과를 비교/채택할 수 있도록 설계됨.
- 사용자는 Braintrust 내에서 Loop 기능을 활성화할 수 있으며, Claude 4 외에도 OpenAI, Gemini, 자체 LLM 등 다양한 모델을 선택하여 이용 가능함.
- 평가(Eval) 방식이 근본적으로 변화하고 있는 시점임을 강조하며, Loop와 함께 미래의 평가 혁신에 동참할 것을 독려함.
- 영상을 마치며 제품에 대한 피드백, 인재 채용 문의, 직접적인 대화 등 적극적인 소통을 요청함.

---

## 세부 요약 - 주제별 정리

### Braintrust는 AI 제품 개발에서 평가(Eval) 작업이 필수적임을 수치로 입증함

- Braintrust의 두 해에 걸친 여정에서 최고의 AI 제품을 만드는 기업들과 협업해옴.
- 자신들이 지원하는 조직의 평균값을 제시: 하루 평균 13건의 평가(Eval) 실행.
- 일부 고객사는 하루 3,000건 이상의 평가를 돌리고 있음.
- 가장 선진화된 고객들의 경우, 하루평균 2시간 이상을 평가에 투자할 정도로 평가가 업무의 핵심임.
- 이처럼 빈번하고 정교한 평가 활동이 AI 제품·에이전트의 성능을 끌어올리는 기반임을 강조함.

### 기존의 평가(Eval) 프로세스는 대부분 수동식 대시보드 활용에 그침

- 데이터, 프롬프트, 코드 등 다양한 구성 요소의 품질을 평가하기 위해 대시보드를 반복적으로 확인해야 함.
- "아주 멋진 대시보드이긴 하지만", 대시보드를 확인한 뒤 개선점(주로 코드, 프롬프트 등)을 별도로 반영해야 하는 번거로움을 언급.
- AI 제품 및 에이전트가 아무리 자동화되어 있어도, 평가는 매우 수동적으로 이루어져 왔음을 지적함.
- 이러한 절차가 AI 개발 현장에서의 리소스 낭비일 수 있음을 시사함.

### 최신 모델(특히 Claude 4)의 등장으로 평가 과정 자동화가 가능해짐

- Braintrust는 분기마다 프론티어 모델(최첨단 대형언어모델)에 대해 직접 평가를 수행해 옴.
- 과거에는 모델들이 프롬프트 개선, 데이터셋 개선, 채점 기준 개선 등 평가 최적화에 기대 이하의 성능을 보였음.
- Claude 4의 도입이 결정적 전환점이 됨.
- Claude 4는 이전 선두 주자 모델 대비, 평가(프롬프트/데이터/채점) 영역에서 최대 6배 뛰어난 결과를 보임.
- 이러한 발전이 'Loop'와 같은 평가 자동화 에이전트의 실현을 가능케 함.

### Loop는 평가 자동화와 고도화를 동시에 실현하는 에이전트 도구임

- Braintrust 내부에서 작동하는 신기능 에이전트 'Loop'를 소개함.
- 평가 자동 최적화: 사용자의 프롬프트, 데이터셋, 채점 기준을 자동으로 분석, 수정 제안 혹은 직접 변경해줄 수 있음.
- 기존 대비 차별점은 Loop가 '평가 자체'의 개선을 포괄적으로 지원한다는 점임(프롬프트·데이터·채점 기준을 모두 최적화).
- 평가 결과와 수정 제안을 UI상에서 나란히 비교, 직접 채택 여부를 판단할 수 있음.
- 보다 적극적인 사용자를 위해 '자동 최적화 토글'을 제공, 완전 자동화도 가능함.

### 다양한 대형언어모델(LLM)과 호환 가능한 Loop 기능으로 접근성을 높임

- Loop는 기본적으로 Claude 4를 사용하지만, 오픈AI, 구글 Gemini 등 다양한 LLM을 직접 선택해 활용할 수 있음.
- 자체 LLM을 보유한 조직도 Loop를 활용 가능함.
- 기존 Braintrust 사용자는 단순히 'Loop' 기능 플래그를 켬으로써 즉시 기능을 사용 가능함.
- Loop 기능은 UI 내부에서 즉각적으로 작동, 별도의 복잡한 연동 작업 없이 곧바로 실전업무에 투입할 수 있도록 설계됨.

### 평가(Eval) 작업 방식이 향후 1년 내 근본적으로 변화할 것임을 확신함

- 최근의 최신 프론티어 모델 등장으로, 평가 자동화의 정확도와 효율성이 크게 향상됨.
- Braintrust는 이러한 변화의 조류를 내부 제품에 적극적으로 반영 중임.
- 전통적인 수동 평가 방식은 점차 사라지고, 평가 자체의 구조가 혁신될 것임을 예견함.
- 앞으로의 1년이 평가 분야의 혁신기에 본격적으로 진입하는 분기점임을 강조.

### 사용자 피드백과 적극적인 채용을 통해 제품과 조직의 혁신을 도모함

- Braintrust의 평가 혁신과 Loop 기능에 대해 사용자의 다양한 피드백을 받고 싶다는 의사를 밝힘.
- UI·AI·인프라 등 다양한 부문에서 함께 일할 인재를 적극 채용 중임을 강조.
- 영상 말미에 QR 코드 안내와, 모든 논의에 열려 있음을 마지막으로 재차 언급함.
