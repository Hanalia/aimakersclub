---
author: AI Makers Club
pubDatetime: 2025-12-02T23:47:26.631Z
title: "Building Cursor Composer - Lee Robinson, Cursor"
slug: fL1iJHtl51Q
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "본 영상은 Cursor의 엔지니어링/리서치 팀을 대표해 Lee Robinson이 ‘Cursor Composer’ 에이전트 모델의 개발 과정과 구조, 기술적 도전, 실제 운영 경험을"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/fL1iJHtl51Q/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [Building Cursor Composer – Lee Robinson, Cursor](https://www.youtube.com/watch?v=fL1iJHtl51Q)  
**채널명:** AI Engineer

## *Cursor Composer 구축 – 실제로 빠르고 똑똑한 소프트웨어 엔지니어링 에이전트 만들기* 핵심 요약

- 본 영상은 Cursor의 엔지니어링/리서치 팀을 대표해 Lee Robinson이 ‘Cursor Composer’ 에이전트 모델의 개발 과정과 구조, 기술적 도전, 실제 운영 경험을 상세히 설명함.
- ‘Cursor Composer’는 실사용 소프트웨어 엔지니어링을 목표로 고속(속도)과 높은 지능(스마트)을 동시에 추구하며, 내부 벤치마크 측정에서 오픈소스 최고 모델들보다 우수, Frontier(최신 상용) 모델에 근접하는 성능을 가짐.
- 토큰 생성 효율성은 동급 지능 모델 대비 약 4배 뛰어나며, 이는 병렬 툴 호출, 자체 시맨틱 서치 도구 등의 인프라 및 아키텍처 개선 덕분임.
- Cursor 팀은 기존 탭(Tab) 오토컴플리트 모델 경험을 확장, 저지연성 코딩 에이전트를 위한 RL(강화학습)과 병렬 도구 호출을 도입하여 ‘빠르고 똑똑한’ 사용성을 목표로 삼음.
- 실제 Cursor 서비스 환경과 동일한 환경에서 RL 학습·검증을 반복하는 인프라 구축에 집중, 여러 VM(가상 머신) 클러스터와 서버, Custom 커널 등 대규모 분산 학습 시스템을 개발함.
- 모델 에이전트는 ‘파일 읽기/편집’, 코드베이스 검색, 린트, 터미널 명령 등 약 10개 툴을 상황에 맞게 병렬·직렬로 호출하여 코딩을 자동화함.
- 자체 임베딩 모델을 활용한 시맨틱 서치를 통해 파일 찾기 및 편집 추천 정밀도가 올랐으며, 실험에서 Composer뿐 아니라 모든 Cursor 에이전트 성능이 개선됨을 확인.
- Composer 전체의 RL 학습 및 실제 운영 경험을 통해 모델이 불필요한 수정은 줄이고, 더 효과적으로 코드 검색/이해/작업 단계를 스스로 개선하는 모습을 보임.
- 인프라 속도를 위한 저정밀 학습(Custom 커널) 및 멀티스레드 작업 분산, VM 오케스트레이션 등의 엔지니어링 과제가 모델 성공의 핵심으로 작동함.
- 최종적으로 2.0 버전 공개 한 달만에 많은 이용자가 긍정적 반응을 보였으며, "코딩 에이전트의 새 프로그래밍 경험(동기적, 실시간, Flow 유지)"을 제공함을 강조.

---

## 세부 요약 - 주제별 정리

### Cursor Composer 모델은 빠르고 실제로 쓸 수 있는 코딩 에이전트를 목표로 개발되었음

- Cursor Composer는 실세계 소프트웨어 엔지니어링을 위해 설계된 최초의 에이전트 모델임.
- 핵심 목표는 “빠르면서도 똑똑하게” 실사용 환경에서 코딩을 지원하는 것이었음.
- 내부 벤치마크에서 오픈소스 최고 모델(예: StarCoder, DeepSeek 등) 대비 뛰어난 성능을 보이며, Frontier 계열 모델(GPT-5.1 Codex, Sonnet 45 등)과 유사하지만 약간 아랫단에 위치함.
- 토큰 생성 속도는 유사 지능 모델 대비 약 4배 빠름(효율성 중점 설계).
- 모델 개발은 “속도와 스마트함 모두 필수”라는 실사용자 피드백에 기반했음.

### RL(강화학습)과 Cursor 실서비스 환경을 일치시키는 것이 학습 품질 제고의 핵심이었음

- RL(강화학습)을 적용, 실제 Cursor 서비스와 최대한 같은 환경에서 모델을 반복적으로 테스트하고 개선함.
- 학습 시 실제 Cursor 툴 사용 시나리오(파일 읽기, 편집, 검색, 린트, 터미널 명령)를 벤치마크로 삼음.
- 사용자 질의에 대해 에이전트가 상황에 따라 직렬 또는 병렬로 여러 도구를 호출함.
- RL을 통해 다양한 Tool 사용 조합을 실험하며, 최적 출력 결과에 따라 모델 파라미터를 갱신함.

### 대규모 학습 환경 구축 과정에서 속도 및 일관성 등 인프라 측면의 세 가지 난제를 경험함

- 첫째, “학습-추론 환경 일치”가 필요한데, 병렬화·샘플링 환경의 차이 극복이 필요함.
- 둘째, 실제 데이터 기반 롤아웃(rollout)은 수십만~수백만 토큰, 수백~수천 번의 Tool 호출 등 매우 복잡해짐.
- 셋째, 프로덕션과 동일한 Tool 포맷/반환 값 일치와 Burst성(일시 과부하) 컴퓨팅 문제(실제 운영 vs 훈련 환경 차이).
- 이 세 가지 모두 모델링이 아니라 인프라 엔지니어링, 시스템 오버헤드 해결이 핵심임.

### 분산 서버 아키텍처와 커스텀 저정밀 학습 커널로 대규모 빠른 학습이 가능해졌음

- 세 개의 주요 서버(트레이너, 추론 서버, 환경 시뮬레이터)로 분산 아키텍처를 구성함.
- PyTorch 기반 표준 ML 스택, Ray 프레임워크를 활용한 rollout 관리, 실제 서비스 환경 시뮬레이션 서버가 모두 통신하며 상호작용함.
- 자체 개발한 저정밀(custom) 커널 라이브러리를 통해 Mixture of Experts layer 학습 속도를 Nvidia Blackwell 칩 기준 약 3.5배 향상시킴.
- 환경 서버 간 작업 부하 분산(Load balancing) 처리로 작업 대기시간/버림 시간 최소화.

### VM 기반 클라우드 환경이 RL 학습 및 실제 제품 운영 모두에 핵심 기반이 되었음

- Cursor의 Cloud Agents 제품(에이전트를 웹/모바일/Slack 등에서 구동)은 각 사용자의 코드를 VM(가상머신)에 로드, 보안 샌드박스에서 파일 편집/툴 실행을 가능케 함.
- 이 클라우드 VM 인프라는 RL 학습 데이터 환경을 실제 서비스와 동일하게 맞추는 데 이상적임.
- 실서비스 및 학습 환경 모두 다수의 클러스터, 수십만 VM 오케스트레이션 필요 — 이를 위한 대시보드 및 관리 툴 개발.
- 훈련 워크로드의 Burst성(Burst workload) 문제, VM 간 작업 분배 등 인프라 과제 해결이 병행됨.

### 시맨틱 서치와 자체 임베딩 모델이 모델 성능 상승에 결정적인 역할을 함

- 자체 임베딩 모델을 훈련, 시맨틱 서치를 통해 코드베이스를 인덱싱하여 자연어 입력 기반 파일 검색 기능을 구현함.
- 실험 결과 시맨틱 서치는 Composer를 비롯한 Cursor 에이전트 전체에서 성능 향상 효과가 극대화됨.
- 환경 일치(동일한 도구셋·포맷)와 시맨틱 서치 습득이 모델의 “파워유저”화에 기여함.

### RL 학습 과정에서 모델이 실제 에이전트다운 행동을 스스로 습득해 나감

- RL을 반복하며 성능이 점진적으로 향상, 최종적으로 Frontier 급 코드 에이전트 성능에 가까워짐.
- 불필요한 코드 수정(Over-editing) 빈도 감소, 충분한 코드 검색/분석 후 최적 위치에만 수정을 수행하는 식으로 행동 변화가 나타남.
- 툴 병렬 호출(예: 파일 10개를 동시에 읽기 등)이 Composer의 속도를 실제로 크게 높임.
- 모델이 진짜 “에이전트”답게 문제를 파악·수행하는데 적응하는 모습이 데이터로 확인됨.

### 2.0 버전 런칭 및 도입 이후 사용자 프로그래밍 경험이 근본적으로 변화함

- Composer 1을 탑재한 Cursor 2.0 출시 이후, 실제로 많은 사용자가 시연 및 실사용에 긍정적 피드백을 제공함.
- 과거(초기 코딩 에이전트 시절)에는 “비행기 와이파이처럼” 느려서 불만이 많았으나, Composer는 동기적(실시간), 사용자의 flow를 유지하는 방식으로 “직접 코드 작성을 하던 시절”에 가까운 경험을 제공하게 됨.
- 최신 Frontier 모델(GPT 5.1 Codex 등)로 플랜을 세우고, Composer로 구체적 구현을 빠르게 진행하는 등 “새로운 프로그래밍 워크플로우”를 지원.

### RL 및 인프라 고도화가 특화 코딩 모델의 품질 및 팀 생산성 전체에 긍정적 파급효과를 가져옴

- RL(강화학습)은 충분한 데이터, 적정 컴퓨트 투입 시 특화 모델에 매우 효과적임이 입증됨(AGI 지향 아님).
- Cursor 자체도 Cursor를 활용해 모든 엔지니어링/리서치 생산성을 크게 높이고 있음.
- 인프라 개선과 ML(머신러닝) 연구의 경계가 실제 개발에선 매우 밀접하게 맞닿아 있음(버셀에서의 경험과 유사).

### Composer 개발에서 얻은 핵심 교훈은 데이터 품질·인프라·환경 일치의 중요성이었음

- 다양한 ML 연구와 데이터 설계의 성공적 적용은 대규모 신뢰할 수 있는 인프라 없이는 불가능함.
- 실제 운영 환경과 학습 환경의 일치가 모델 품질에 직접적 영향을 미침.
- 코딩 에이전트의 미래는 보다 동기적이고 빠르며, 실세계 문제해결에 밀착한 “flow 지원” 방식임을 강조.

### 커서에서는 최고 코딩 모델 개발을 위한 인재 채용도 적극 진행 중임

- 뉴욕 등에서 사무실을 오픈, 모델 연구 및 엔지니어링 전 분야로 채용 확대 중임(영상 후반 언급).
- 최고의 코딩 모델 개발 및 실제 적용에 관심 있는 사람이라면 팀에 합류할 것을 권유함.
