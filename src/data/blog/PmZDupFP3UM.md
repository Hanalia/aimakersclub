---
author: AI Makers Club
pubDatetime: 2025-12-19T23:46:56.399Z
title: "Leadership in AI Assisted Engineering - Justin Reock, DX (acq. Atlassian)"
slug: PmZDupFP3UM
featured: true
draft: false
tags:
  - AI
  - YouTube 요약
  - 자동 업로드
description: "발표자는 DX(Atlassian에 인수된 개발자 생산성 및 경험 측정 전문 기업)의 Justin Reock으로, AI 도입이 개발 생산성에 미치는 실제적 영향과 리더십 방향성에 대"
---

<div style="text-align: center;">
  <img src="https://img.youtube.com/vi/PmZDupFP3UM/maxresdefault.jpg" alt="YouTube Thumbnail" style="width: 100%; max-width: 640px; height: auto; border-radius: 0.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" loading="lazy" />
</div>

**영상 링크:** [Leadership in AI Assisted Engineering – Justin Reock, DX (acq. Atlassian)](https://www.youtube.com/watch?v=PmZDupFP3UM)  
**채널명:** AI Engineer

## *AI 지원 엔지니어링에서의 리더십 – Justin Reock, DX (acq. Atlassian)* 핵심 요약

- 발표자는 DX(Atlassian에 인수된 개발자 생산성 및 경험 측정 전문 기업)의 Justin Reock으로, AI 도입이 개발 생산성에 미치는 실제적 영향과 리더십 방향성에 대해 설명함
- Google은 AI의 도입으로 10%의 생산성 증가를, 다른 연구(METER MER)에서는 19%의 생산성 감소를 발표하는 등, AI 효과에 대한 지표와 체감 차이가 크게 나타남
- DX 및 Dora의 대규모 데이터 분석 결과, AI 도입 후 문서 품질(7.5%), 코드 품질(3.4%), 변경 신뢰도(2.6~6%), 변경 실패율(1%) 등에서 '평균적으로' 소폭의 긍정적 효과가 있었으나, 회사별 편차가 매우 큼
- 일부 조직은 KPI가 크게 개선된 반면, 다른 조직은 오히려 부정적 결과를 경험했으며, 도입률 증가만을 강조하거나 교육·지원 부족, 정확한 성과 측정의 어려움 등 구조적 문제가 다수 발견됨
- AI 도입의 긍정적 효과를 극대화하기 위해서는 SDLC 전체 통합, 사용자의 적극적 사용 지원, 심리적 안전감 조성, 충분한 교육·학습 시간 제공이 중요함
- 생산성·품질(속도와 질)이라는 핵심 지표를 중심으로 한 다각적 측정이 필요하며, 단순 API 이용률 등은 실제 영향력을 제대로 반영하지 못함
- DX는 활용도/영향/비용 기반의 자체 측정 프레임워크(DXAI)를 제안, 실사용 분석 및 성과 상관관계를 수치화함
- 사례로 Morgan Stanley(Dev Gen AI 통해 연간 30만 시간 절감), Zapier(온보딩 기간 2주로 단축·신규 채용 확대), Spotify(SRE 지원 자동화로 인시던트 대응시간 감소) 등 실제 AI 적용 기업들의 구체적 성과가 소개됨
- 효과적 AI 도입을 위해 각각의 조직 상황에 맞춰 '목표설정-성과측정-개선' 루프를 가지며, 심리적 저항을 낮추고 직원 성공과 연계한 리더십이 요구됨

---

## 세부 요약 - 주제별 정리

### AI 효과에 대한 산업 전반의 지표는 산발적이고 편차가 크다는 사실이 드러남

- Google은 생성형 AI(GenAI) 도입 후 평균 10% 생산성 향상이라는 자체 데이터를 발표함
- 반면, MER 연구에서는 코드 지원 도구 도입이 오히려 19% 생산성을 저하시켰다는 결과로 논란이 됨
- 해당 연구에 참여한 엔지니어들은 "생산성이 높아졌다"고 느꼈으나, 실제 계량 데이터상엔 감소가 기록됨
- Dora 등 신뢰성 있는 산업 데이터도 평균적으로는 긍정적이지만, 편차(variance)가 매우 큼
- 개발자 경험, 심리적 ‘몰입감’(induced flow) 등의 착시적 효과와 실제 결과의 차이를 구분해야 함
- 전체 표본 대비 회사별 결과 차이가 매우 커, 같은 AI 기술을 도입하고도 20% 성과 증진과 20% 성과 저하를 각각 경험한 케이스가 존재함

### 조직의 AI 도입 방식에 따라 성과가 천차만별로 나타나며 평균 데이터만으론 한계가 있음

- 전체 평균치는 소폭 향상처럼 보이나, 개별 회사 단위로 보면 변화 폭이 극단적으로 큼
- 변경 신뢰도(change confidence), 코드 유지보수성, 변경 실패율(change failure rate) 등 주요 지표에서 회사별로 +20%~ -20%까지 넓게 분포
- 같은 산업군에서도 도입 전략, 리더십, 교육 방식에 따라 극과 극의 결과가 도출됨
- industry benchmark(산업 표준)로 보는 변경 실패율이 4%일 때, 회사에 따라 2% 증가 시기도 있음
- 단순히 'AI 100% 도입'을 지시하는 탑다운 방식(top-down mandate)은 무의미하며, 실질적 변화를 이끌지 못함

### AI 활용의 성공/실패를 가르는 핵심은 도입 전략, 교육, 문화적 안전감에 있음

- 형식적 도입(“매일 readme 파일만 업데이트” 등)은 조직 효율에 기여하지 않음
- AI 도입에 따른 효과 측정 지표/필요 데이터가 불명확한 경우가 많음
- 결정적 요인으로는 ▷명확한 AI 정책 수립 ▷실질적 학습시간(공부+실습 시간) 보장 ▷정기적 wins 공유 등 오픈 커뮤니케이션이 제시됨
- 엔지니어가 “AI가 내 일자리를 대신할까” 하는 불안을 느끼지 않게 심리적 안전장치 필요

### SDLC 전체에 AI를 창의적으로 통합하고, 사용 장벽을 허물어야 실질적 효과가 발생함

- 기존 생산성 병목은 대체로 ‘코드 작성’이 아니라, 리뷰/배포/사이드 이펙트 관리 등에서 발생
- 주저없이 AI 실험을 해볼 수 있는 안전한 환경(예: AWS Bedrock, Fireworks AI 등 사설 클라우드 기반 인프라)이 마련되어야 함
- 데이터 유출 등 보안 우려로 도입 자체를 지연하기보단, 기술적·컴플라이언스적 대안을 모색해야 함
- 내부 BI팀·엔지니어들과의 지속적 대화와 데이터 공유, 성공사례 전파가 중요

### AI 도입에 대한 심리적 저항감을 줄이고, ‘대체’가 아닌 ‘강화’임을 명확히 해야 함

- Google의 ‘프로젝트 아리스토텔레스’(2012) 연구에서 최고 성과팀의 핵심은 심리적 안전감(psychological safety)임이 입증됨
- AI가 엔지니어를 완전히 대체하지 못함 (예시: SweetBench 벤치마크에서 3분의 1 작업만 무인처리 가능, 3분의 2는 여전히 인간 필요)
- “AI는 증강(augment)이며, 개발자 및 조직 생산성 강화를 위한 도구”임을 명확히 하는 리더의 역할이 중요
- AI 도입 의도를 투명하게 설명하고 부정적 불안이 생기기 전에 적극적으로 커뮤니케이션할 필요

### AI 효과 측정에는 신뢰성 있는 생산성·품질 지표 중심의 종합적 접근이 필요함

- AI 관련 메트릭스의 핵심은 ▷속도(PR 처리량, velocity) ▷품질(실제 제품 안정성, 변경 실패율 등)
- Telemetry(서비스/API 기록) 지표는 실제 값과 괴리가 있음(예: ‘accept’ 클릭만으로 만족도 판단 어려움, 실제론 제안 모두 수정 가능)
- 경험 샘플링(실 PR에 ‘AI 사용 여부’ 체크란 추가) 및 개발자 자기보고식(설문) 데이터가 보조적 역할
- 설문 설계 시 “사람의 문제”가 아니라 “시스템의 문제”로 간주하여 90% 이상 응답률을 목표로 함 (W. Edwards Deming 원칙 인용)
- AI 자체 활용률보다, “근본적 개발 경험/생산성 지표”가 실제 변화를 보여주는 주요 척도임

### 실제 AI 활용 기업의 성과 사례들이 증가함에 따라 측정 프레임워크의 정형화가 진행되고 있음

- Microsoft: AI 채택률 및 ‘bad developer day(불편한 작업일)’ 등 체험적 지표 도입
- Dropbox, Booking: DAU/WAU 등 활용률 대비 변경 실패율 등 품질 지표 동시 추적
- DX: Dora와 DevX 프레임워크(핵심 4대 지표) 기반으로 활용도, 영향, 비용의 3차원 벡터로 성숙도·효과를 측정하는 DXAI 프레임워크를 구축
- 측정 프레임워크는 ①누가, 얼마나 AI를 쓰는가(활용도) ②그 결과 실제 생산성/품질이 어떻게 변화하는가(영향) ③AI 사용에 따른 비용적 효율(비용) 등 단계로 성숙됨
- AI 도입 초기는 단순 ‘체험률’ 측정에서 시작, 단계적으로 실제 비즈니스 임팩트 및 비용 효율로 확장

### ‘시스템 프롬프트’ 등 모델 운용 규칙 설계와 지속적 피드백 루프가 신뢰 확보의 핵심임

- 메인스트림 AI 엔지니어링에서는 대부분 ‘시스템 프롬프트’(규칙), ‘커서 룰’, ‘에이전트 마크다운’ 등 규범 정의 기능을 지원함
- 예시: Spring Boot 3버전만 쓰고 싶은데 프롬프트가 계속 2버전 코드를 만들어낼 때, 피드백 루프를 통해 개선 및 업데이트 필수
- 조직 내 ‘게이트키퍼’(책임자)를 두고 지속적 피드백 및 규칙 갱신 체계 마련 권장
- 생성모델의 ‘temperature’(난수성/창의성) 값을 상황에 따라 조정(0~1), 더 높은 창의성이나 더 높은 일관성 중 목적에 따라 밸런스 필요
- Docker model runner, LLama LM Studio 등 자유도 높은 실험 도구도 소개됨

### 직원 성공과 AI 활용 능력의 직결성을 인식하고, 맞춤형 교육·경험 기회를 제공해야 함

- AI로 한 주에 1시간 이상을 절약하는 개발자들을 대상으로 가장 가치 있는 활용사례(top5)를 조사
- 결과를 바탕으로 코드 예시, 프롬프트 사례 등 실전 가이드북을 제작하여 내부 필독서로 채택
- 가장 많이 활용되는 AI 사용법은 ‘스택 트레이스 분석’으로, 생성형보단 해석형 유즈케이스가 상위권
- 맞춤형 교육과 실제 업무 적용 시간(교육+실습)의 보장이 필수임을 명확히 함

### 활용 장벽 해소를 위해 자체 모델, 사설 인프라, 컴플라이언스 협업 등 다양한 방법이 부상함

- 자체 호스팅/프라이빗 AI 모델 도입이 기술적으로 쉬워지고 있음
- 컴플라이언스(규정준수) 부서와 초기 단계부터 협력해 조직의 가정과 제한을 재검증할 필요
- 표면적 보안 우려로 모든 도입을 멈추기보단, 창의적 해결책(프라이빗 서버, 특정 파티션 등)을 활용

### SDLC 병목 요소를 정확히 찾아, AI의 강점을 실질적인 병목 해소에 할당해야 함

- 단순 코드 작성 속도 개선만으로는 전체 생산성 병목이 해결되지 않음
- 약 14만 명의 데이터 분석 결과, AI가 연 단위로 절감하는 시간보다, 미팅·컨텍스트 스위칭 등에서 소모되는 시간이 여전히 큼
- 병목을 먼저 식별하고 그 부분에 AI를 집중 투입해야 전체 개선 효과가 극대화됨
- Morgan Stanley: ‘Dev Gen AI’로 레거시 코드 자동화(연 30만 시간), 현재 공개 사례로 논문 및 기사 발표
- Zapier: AI 에이전트/봇이 온보딩 프로세스를 자동화, 신규 엔지니어 셋업 기간을 2주로 단축(업계 평균 1달~3달), 비용절감이 아닌 채용 가속으로 이어짐
- Spotify: SRRE팀의 인시던트 대응 절차 자동화로 평균 복구시간(MTTR) 단축, 컨텍스트/문서가 자동으로 SRE 채널로 전달됨

### AI 도입에 있어 ‘목표-측정-개선’의 선순환과 직원 성장·만족 연결이 장기적 성과의 핵심임

- 가이드/플레이북 등 명확한 참고자료를 조직 내 배포, 실전 워크플로우에 통합
- GenAI 영향 측정/평가 방법 체계화, 주요 임팩트 지표와 AI 도입률의 상관관계 파악, 실시간으로 사용사례/베스트프랙티스 갱신 필요
- 경영진의 적극적 리더십과, 개별 직원이 변화에 성장할 수 있도록 도와주는 지원 체계가 요구됨
